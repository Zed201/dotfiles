{"clipboardHistory":[{"value":".config/clipse/tmp_files/","recorded":"2025-04-15 21:26:13.077294115","filePath":"null","pinned":false},{"value":"PASTAS=( \"anyrun\" \"code-flags.conf\" \"hypr\" \"nvim\" \"waybar\" \"wireplumber\" \"wofi\" \"clipse\" \"htop\" \"mako\" \"scripts\" \"waypaper\" \"wlogou\" )\n","recorded":"2025-04-15 21:25:09.294583520","filePath":"null","pinned":false},{"value":"anyrun  code-flags.conf  hypr  nvim     waybar    wireplumber  wofi\nclipse  htop             mako  scripts  waypaper  wlogou","recorded":"2025-04-15 21:23:54.711922573","filePath":"null","pinned":false},{"value":"#!/bin/bash\n\n# Array de pastas a serem backupadas\nPASTAS=( \"nome_da_pasta1\" \"nome_da_pasta2\" \"nome_da_pasta3\" )\n\n# Caminho para a pasta de destino\nDESTINO=~/.config/backup\n\n# Criar a pasta de destino se n√£o existir\nmkdir -p \"$DESTINO\"\n\n# Copiar cada pasta para a pasta de destino\nfor pasta in \"${PASTAS[@]}\"; do\n  cp -r \"$HOME/.config/$pasta\" \"$DESTINO/$pasta\"\ndone","recorded":"2025-04-15 21:20:42.083268028","filePath":"null","pinned":false},{"value":"}","recorded":"2025-04-15 21:19:02.356144676","filePath":"null","pinned":false},{"value":"#!/bin/bash\n\n# Script para fazer backup e push autom√°tico\n\ntimestamp=$(date +\"%Y-%m-%d_%H-%M-%S\")\ncommit_message=\"backup $timestamp\"\n\ngit add .\ngit commit -m \"$commit_message\"\ngit push\n\necho \"Backup e push realizados: $commit_message\"","recorded":"2025-04-15 21:13:35.779836315","filePath":"null","pinned":false},{"value":"#!/bin/bash\n\n# Script para fazer backup autom√°tico com data/hora\n\n# Obt√©m a data e hora no formato YYYY-MM-DD_HH-MM-SS\ntimestamp=$(date +\"%Y-%m-%d_%H-%M-%S\")\n\n# Mensagem do commit\ncommit_message=\"backup $timestamp\"\n\n# Executa os comandos git\ngit add .\ngit commit -m \"$commit_message\"\n\n# Mostra mensagem de confirma√ß√£o\necho \"Backup realizado: $commit_message\"","recorded":"2025-04-15 21:13:27.969172088","filePath":"null","pinned":false},{"value":"git rm -r --cached .","recorded":"2025-04-15 21:11:27.564794935","filePath":"null","pinned":false},{"value":"it push --set-upstream origin master","recorded":"2025-04-15 21:00:50.057750869","filePath":"null","pinned":false},{"value":"git@github.com:Zed201/obsidian_notes.git","recorded":"2025-04-15 20:58:37.436377757","filePath":"null","pinned":false},{"value":" yay -cc\nerror: invalid option: '--clean' and '--refresh' may not be used together","recorded":"2025-04-15 20:39:36.555253038","filePath":"null","pinned":false},{"value":"--currentconfig","recorded":"2025-04-15 20:37:10.484065846","filePath":"null","pinned":false},{"value":"\u003e aciel (prmm@cin.ufpe.br) Abstract‚ÄîVehicular Cloud Computing (VCC) introduces a new challenge to cloud computing: resource volatility, as vehicles may leave the cloud unpredictably. This study proposes a Stochas- tic Petri-Net (SPN) model with a container allocation technique to analyze the performance of static vehicular clouds. We developed an architecture within the context of a car rental business to evaluate task discard probability and resource utilization. Our baseline results show a low task discard probability (QDP = 1.68%) and high resource utilization (U = 74.90%). Case studies further demonstrate that adjusting the number of tasks running per vehicle and varying task service time significantly impact these metrics. Our results provide insights for optimizing static vehicular cloud implementation, focusing on minimizing task discards and maximizing resource utilization. I. INTRODUCTION Nowadays vehicles have increasing processing, sensing, and storage power, and those resources are often underutilized on the roads and parking lots [1]. Thus, similar to the concept of conventional cloud computing, the term Vehicular Cloud Computing (VCC) emerges [2, 3, 4, 5]. The primary goal of VCC is to enable vehicle computers to be used similarly to conventional cloud computing, as much as the limitations allow. Previous work defined two types of VCC: static and dy- namic [5]. In static VCC, vehicles enter the vehicular cloud as soon as they enter a static environment such as parking lots [6]. Thus, in this context, the storage capacity and processing power of vehicles can be used similarly to a conventional cloud computing environment. In dynamic VCC, vehicles moving at high speeds elect one vehicle to act as a broker to form a VCC. The broker then invites other vehicles in the perimeter to enter the cloud. When a sufficient number of vehicles enter the cloud, the broker consolidates the VCC formation, gathering the storage capacity and processing power of all cars involved [6]. One of the main challenges faced by VCC is the volatility of the environment [1, 7]. As vehicles move on the roads, or even, park in places, they may become unavailable at some point, either by moving to a different direction on the road or by leaving the parking lot after shopping at a mall. These situations imply that the vehicle and its resources leave the cloud. Consequently, resource availability in VCC is unpredictable. In the context of static VCC, a vehicle needs to stay in the static environment for enough time to perform the assigned tasks. However, this is not always viable. Leading to the discard of work. Hence, researchers propose different approaches to deal with this problem [1]. One of the solutions to this problem is using the concept of checkpointing, borrowed from database [8]. This approach maintains an ‚Äùalmost up-to-date‚Äù backup copy of the ongoing work on a different storage. This ensures that, whenever a currently working vehic\n\n[[Performance_Evaliation_of_Static_Vehicular_Clouds.pdf#page=1\u0026selection=6,40,86,25|Performance_Evaliation_of_Static_Vehicular_Clouds, p√°gina 1]]","recorded":"2025-04-15 17:25:00.330101959","filePath":"null","pinned":false},{"value":"üì∑ 76217-060524111.png","recorded":"2025-04-15 17:07:24.096705037","filePath":"/home/guga/.config/clipse/tmp_files/76217-060524111.png","pinned":false},{"value":"üì∑ 63484-964532607.png","recorded":"2025-04-15 17:05:15.001949003","filePath":"/home/guga/.config/clipse/tmp_files/63484-964532607.png","pinned":false},{"value":"qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: xcb.","recorded":"2025-04-15 16:50:02.075260165","filePath":"null","pinned":false},{"value":"https://github.com/zhichaoh/catppuccin-wallpapers.git","recorded":"2025-04-15 14:44:55.322110611","filePath":"null","pinned":false},{"value":"git commit -m \"anyrun, pyprland e wall\"","recorded":"2025-04-15 14:41:24.675360799","filePath":"null","pinned":false},{"value":"#include \"src/defines.h\"","recorded":"2025-04-14 20:35:07.217893838","filePath":"null","pinned":false},{"value":"            this-\u003emin = min_(this-\u003emin, i);","recorded":"2025-04-14 20:32:22.289760346","filePath":"null","pinned":false},{"value":" ","recorded":"2025-04-14 20:32:09.983013054","filePath":"null","pinned":false},{"value":"        this-\u003en_dim = a;","recorded":"2025-04-14 20:31:50.447949161","filePath":"null","pinned":false},{"value":"git@github.com:Zed201/np_clone.git","recorded":"2025-04-14 20:25:44.819045133","filePath":"null","pinned":false},{"value":"kitty +kitten panel ‚Äîclass cava_background ‚Äîedge=background -o background_opacity=0 -o font_size=1 cava","recorded":"2025-04-14 20:13:08.280805013","filePath":"null","pinned":false},{"value":"kitty +kitten panel --edge=background cava","recorded":"2025-04-14 20:12:19.169101413","filePath":"null","pinned":false},{"value":"ix-darwin.","recorded":"2025-04-14 20:07:32.478198355","filePath":"null","pinned":false},{"value":"üì∑ 257435-175251333.png","recorded":"2025-04-14 20:05:39.295170115","filePath":"/home/guga/.config/clipse/tmp_files/257435-175251333.png","pinned":false},{"value":"ags-hyprpanel-git","recorded":"2025-04-14 17:27:57.934067811","filePath":"null","pinned":false},{"value":"üì∑ 155737-567917455.png","recorded":"2025-04-14 17:26:41.757620500","filePath":"/home/guga/.config/clipse/tmp_files/155737-567917455.png","pinned":false},{"value":"üì∑ 200328-312612595.png","recorded":"2025-04-14 17:24:59.538089059","filePath":"/home/guga/.config/clipse/tmp_files/200328-312612595.png","pinned":false},{"value":"$ hyprshot -m window","recorded":"2025-04-14 17:24:49.183338513","filePath":"null","pinned":false},{"value":"scratchpads","recorded":"2025-04-14 17:20:14.324488794","filePath":"null","pinned":false},{"value":"[scratchpads.term]\nanimation = \"fromTop\"\ncommand = \"kitty --class kitty-dropterm\"\nclass = \"kitty-dropterm\"\nsize = \"75% 60%\"\nmax_size = \"1920px 100%\"\nmargin = 50\n\n[scratchpads.volume]\nanimation = \"fromRight\"\ncommand = \"pavucontrol\"\nclass = \"org.pulseaudio.pavucontrol\"\nsize = \"40% 90%\"\nunfocus = \"hide\"\nlazy = true","recorded":"2025-04-14 17:20:01.341918693","filePath":"null","pinned":false},{"value":"[shortcuts_menu.entries]\n\"entry 1\" = \"command to run\"\n\"entry 2\" = \"command to run\"","recorded":"2025-04-14 17:16:43.050306363","filePath":"null","pinned":false},{"value":"bind = $mainMod , Z, exec, pypr zoom ++0.5\nbind = $mainMod SHIFT, Z, exec, pypr zoom","recorded":"2025-04-14 17:13:41.898464640","filePath":"null","pinned":false},{"value":"hyprpanel","recorded":"2025-04-14 17:08:50.558298766","filePath":"null","pinned":false},{"value":"# Setup the key binding\nbind = $mainMod, B, exec, pypr expose\n\n# Add some style to the \"exposed\" workspace\nworkspace = special:exposed,gapsout:60,gapsin:30,bordersize:5,border:true,shadow:false","recorded":"2025-04-14 17:06:23.462125218","filePath":"null","pinned":false},{"value":"[scratchpads.term]\nanimation = \"fromTop\"\ncommand = \"alacritty --class alacritty-dropterm --config-file ~/.config/alacritty/scratchpad.toml -e bash -c 'zellij attach --create scratch'\"\nclass = \"alacritty-dropterm\"\nsize = \"75% 60%\"\nmax_size = \"1920px 100%\"\nmargin = 50\n\n[scratchpads.volume]\nanimation = \"fromRight\"\ncommand = \"pavucontrol\"\nclass = \"org.pulseaudio.pavucontrol\"\nsize = \"40% 90%\"\nunfocus = \"hide\"\n\n[scratchpads.calc]\nanimation = \"fromTop\"\ncommand = \"foot -f monospace:size=24 -T calculator -e python -ic ''\"\nsize = \"40% 40%\"","recorded":"2025-04-14 17:02:52.703146832","filePath":"null","pinned":false},{"value":"[pyprland]\nplugins = [\"scratchpads\"]\n\n[scratchpads.term]\nanimation = \"fromTop\"\ncommand = \"alacritty --class alacritty-dropterm --config-file ~/.config/alacritty/scratchpad.toml -e bash -c 'zellij attach --create scratch'\"\nclass = \"alacritty-dropterm\"\nsize = \"75% 60%\"\nmax_size = \"1920px 100%\"\nmargin = 50\n\n[scratchpads.volume]\nanimation = \"fromRight\"\ncommand = \"pavucontrol\"\nclass = \"org.pulseaudio.pavucontrol\"\nsize = \"40% 90%\"\nunfocus = \"hide\"\n\n[scratchpads.calc]\nanimation = \"fromTop\"\ncommand = \"foot -f monospace:size=24 -T calculator -e python -ic ''\"\nsize = \"40% 40%\"","recorded":"2025-04-14 17:02:21.748203636","filePath":"null","pinned":false},{"value":"pypr help\nUnhandled exception:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.13/site-packages/pyprland/command.py\", line 512, in main\n    asyncio.run(run_daemon() if invoke_daemon else run_client())\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/asyncio/runners.py\", line 195, in run\n    return runner.run(main)\n           ~~~~~~~~~~^^^^^^\n  File \"/usr/lib/python3.13/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"/usr/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/usr/lib/python3.13/site-packages/pyprland/command.py\", line 449, in run_client\n    await manager.load_config(init=False)\n  File \"/usr/lib/python3.13/site-packages/pyprland/command.py\", line 191, in load_config\n    await self.__open_config()\n  File \"/usr/lib/python3.13/site-packages/pyprland/command.py\", line 107, in __open_config\n    for extra_config in list(config[\"pyprland\"].get(\"include\", [])):\n                             ~~~~~~^^^^^^^^^^^^\nKeyError: 'pyprland'","recorded":"2025-04-14 17:00:59.885997976","filePath":"null","pinned":false},{"value":"apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: \"JOB_NAME_PLACEHOLDER\"  # Ser√° substitu√≠do pelo script\n  labels:\n    kueue.x-k8s.io/queue-name: job-queue\n    kueue.x-k8s.io/priority-class: PRIORIDADE-priority\nspec:\n  ttlSecondsAfterFinished: 4\n  backoffLimit: 4\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: job-name\n                    operator: Exists\n              topologyKey: \"kubernetes.io/hostname\"\n      containers:\n        - name: sleep-job\n          image: busybox\n          command: [\"sh\", \"-c\", \"sleep SLEEP_TIME_PLACEHOLDER\"]  # Ser√° substitu√≠do\n          resources:\n            requests:\n              cpu: 1\n      restartPolicy: Never\n","recorded":"2025-04-14 16:40:05.402910070","filePath":"null","pinned":false},{"value":"apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: \"JOB_NAME_PLACEHOLDER\"  # Ser√° substitu√≠do pelo script\n  labels:\n    kueue.x-k8s.io/queue-name: job-queue\n    kueue.x-k8s.io/priority-class: PRIORIDADE-priority\nspec:\n  ttlSecondsAfterFinished: 4\n  backoffLimit: 4\n  template:\n    spec:\n      affinity:\n        podAntiAffinity: # basicamente usa do affinity para todos os pods com o \n                        # key: job-name eles sejam colocados em nodes diferentes de preferencia\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: job-name\n                    operator: Exists\n              topologyKey: \"kubernetes.io/hostname\"\n      containers:\n        - name: sleep-job\n          image: busybox\n          command: [\"sh\", \"-c\", \"sleep SLEEP_TIME_PLACEHOLDER\"]  # Ser√° substitu√≠do\n          resources:\n            requests:\n              cpu: 1\n      restartPolicy: Never\n","recorded":"2025-04-14 16:38:14.197610373","filePath":"null","pinned":false},{"value":"apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: \"JOB_NAME_PLACEHOLDER\"  # Ser√° substitu√≠do pelo script\n  labels:\n    kueue.x-k8s.io/queue-name: job-queue\n    kueue.x-k8s.io/priority-class: PRIORIDADE-priority\nspec:\n  ttlSecondsAfterFinished: 4\n  backoffLimit: 4\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: job-name\n                    operator: Exists\n              topologyKey: \"kubernetes.io/hostname\"\n      containers:\n        - name: sleep-job\n          image: busybox\n          command: [\"sh\", \"-c\", \"sleep SLEEP_TIME_PLACEHOLDER\"]  # Ser√° substitu√≠do\n          resources:\n            requests:\n              cpu: %d\n      restartPolicy: Never\n","recorded":"2025-04-14 16:14:28.069257702","filePath":"null","pinned":false},{"value":"apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: \"JOB_NAME_PLACEHOLDER\"  # Ser√° substitu√≠do pelo script\n  labels:\n    kueue.x-k8s.io/queue-name: job-queue\n    kueue.x-k8s.io/priority-class: PRIORIDADE-priority\nspec:\n  ttlSecondsAfterFinished: 4\n  backoffLimit: 4\n  template:\n    spec:\n\t\t\taffinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: job-name\n                operator: Exists\n            topologyKey: \"kubernetes.io/hostname\"\n      containers:\n      - name: sleep-job\n        image: busybox\n        command: [\"sh\", \"-c\", \"sleep SLEEP_TIME_PLACEHOLDER\"]  # Ser√° substitu√≠do\n        resources:\n          requests:\n            cpu: %d\n      restartPolicy: Never\n`","recorded":"2025-04-14 16:14:23.526904505","filePath":"null","pinned":false},{"value":"\n","recorded":"2025-04-14 16:13:33.539064263","filePath":"null","pinned":false},{"value":"apiVersion: batch/v1\n\n","recorded":"2025-04-14 16:13:31.342184138","filePath":"null","pinned":false},{"value":"kind: Job\nmetadata:\n  name: \"JOB_NAME_PLACEHOLDER\"  # Ser√° substitu√≠do pelo script\n  labels:\n      kueue.x-k8s.io/queue-name: job-queue\n      kueue.x-k8s.io/priority-class: PRIORIDADE-priority\nspec:\n  ttlSecondsAfterFinished: 4\n  backoffLimit: 4\n  template:\n    spec:\n      containers:\n      - name: sleep-job\n        image: busybox\n        command: [\"sh\", \"-c\", \"sleep SLEEP_TIME_PLACEHOLDER\"]  # Ser√° substitu√≠do\n        resources:\n          requests:\n            cpu: 1\n      restartPolicy: Never","recorded":"2025-04-14 16:13:29.161750054","filePath":"null","pinned":false},{"value":"      - name: sleep-job\n        image: busybox\n        command: [\"sh\", \"-c\", \"sleep SLEEP_TIME_PLACEHOLDER\"]  # Ser√° substitu√≠do\n","recorded":"2025-04-14 16:12:39.803624130","filePath":"null","pinned":false},{"value":"        - name: %s-%s\n          image: %s\n          command: ['sh', '-c', '%s']\n","recorded":"2025-04-14 16:12:32.346313377","filePath":"null","pinned":false},{"value":"\"JOB_NAME_PLACEHOLDER\"  # Ser√° substitu√≠do pelo script\n","recorded":"2025-04-14 16:12:01.019003018","filePath":"null","pinned":false},{"value":"\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: %s\n  labels:\n    kueue.x-k8s.io/queue-name: job-queue\n    kueue.x-k8s.io/priority-class: 1-priority\nspec:\n  ttlSecondsAfterFinished: 4\n  backoffLimit: 4\n  template:\n    spec:\n\t\t\taffinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: job-name\n                operator: Exists\n            topologyKey: \"kubernetes.io/hostname\"\n      containers:\n        - name: %s-%s\n          image: %s\n          command: ['sh', '-c', '%s']\n          resources:\n            requests:\n              cpu: %d\n      restartPolicy: Never\n`","recorded":"2025-04-14 16:02:46.385868219","filePath":"null","pinned":false},{"value":"apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: %s\n  labels:\n    kueue.x-k8s.io/queue-name: job-queue\n    kueue.x-k8s.io/priority-class: 1-priority\nspec:\n  ttlSecondsAfterFinished: 4\n  backoffLimit: 4\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: job-name\n                    operator: Exists\n              topologyKey: \"kubernetes.io/hostname\"\n      containers:\n        - name: %s-%s\n          image: %s\n          command: ['sh', '-c', '%s']\n          resources:\n            requests:\n              cpu: %d\n      restartPolicy: Never\n","recorded":"2025-04-14 16:02:34.975101614","filePath":"null","pinned":false},{"value":"apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: %s\n  labels:\n    kueue.x-k8s.io/queue-name: job-queue\n    kueue.x-k8s.io/priority-class: 1-priority\nspec:\n  ttlSecondsAfterFinished: 4\n  backoffLimit: 4\n  template:\n    spec:\n\t\t\taffinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: job-name\n                operator: Exists\n            topologyKey: \"kubernetes.io/hostname\"\n      containers:\n        - name: %s-%s\n          image: %s\n          command: ['sh', '-c', '%s']\n          resources:\n            requests:\n              cpu: %d\n      restartPolicy: Never","recorded":"2025-04-14 16:01:57.000561942","filePath":"null","pinned":false},{"value":"\nvar jobTample string = `\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: %s\n  labels:\n    kueue.x-k8s.io/queue-name: job-queue\n    kueue.x-k8s.io/priority-class: 1-priority\nspec:\n  ttlSecondsAfterFinished: 4\n  backoffLimit: 4\n  template:\n    spec:\n\t\t\taffinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: job-name\n                operator: Exists\n            topologyKey: \"kubernetes.io/hostname\"\n      containers:\n        - name: %s-%s\n          image: %s\n          command: ['sh', '-c', '%s']\n          resources:\n            requests:\n              cpu: %d\n      restartPolicy: Never\n\n","recorded":"2025-04-14 16:01:19.432710802","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\nimport logging\n\n# Configurar logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"job-controller\")\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    try:\n        nodes = core.list_node().items\n        worker_nodes = [node for node in nodes if not is_controller_node(node)]\n        logger.info(f\"Nodes de trabalho detectados: {len(worker_nodes)}\")\n        return len(worker_nodes)\n    except Exception as e:\n        logger.error(f\"Erro ao buscar nodes: {e}\")\n        return 0\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n    \n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\ndef get_all_jobs():\n    \"\"\"Retorna todos os jobs com status e metadata relevantes\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        job_info = []\n        \n        for job in jobs:\n            # Verificar spec.suspend (pode ser None em jobs antigos)\n            suspended = job.spec.suspend if hasattr(job.spec, 'suspend') and job.spec.suspend is not None else False\n            \n            # Verificar se o job est√° completo ou falhou\n            completed = job.status.succeeded and job.status.succeeded \u003e 0 if hasattr(job.status, 'succeeded') else False\n            failed = job.status.failed and job.status.failed \u003e 0 if hasattr(job.status, 'failed') else False\n            \n            # Verificar se o job est√° ativo\n            active = job.status.active and job.status.active \u003e 0 if hasattr(job.status, 'active') else False\n            \n            # Determinar o estado do job\n            state = \"Completed\" if completed else \"Failed\" if failed else \"Active\" if active else \"Pending\"\n            \n            job_info.append({\n                'name': job.metadata.name,\n                'creation_time': job.metadata.creation_timestamp,\n                'suspended': suspended,\n                'state': state,\n                'active': active,\n                'completed': completed,\n                'failed': failed\n            })\n            \n        return job_info\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs: {e}\")\n        return []\n\ndef enforce_queue_order():\n    \"\"\"\n    Aplica a ordem correta da fila\n    \"\"\"\n    try:\n        with job_lock:\n            worker_nodes = get_num_worker_nodes()\n            if worker_nodes \u003c= 0:\n                logger.warning(\"Nenhum node de trabalho dispon√≠vel\")\n                return\n                \n            # Obt√©m todos os jobs e filtra apenas os que n√£o est√£o completos ou falhados\n            all_jobs = get_all_jobs()\n            pending_jobs = [j for j in all_jobs if j['state'] not in ['Completed', 'Failed']]\n            \n            # Ordena jobs por tempo de cria√ß√£o (mais antigos primeiro)\n            pending_jobs.sort(key=lambda j: j['creation_time'])\n            \n            # Log do estado atual\n            active_count = len([j for j in pending_jobs if j['active']])\n            suspended_count = len([j for j in pending_jobs if j['suspended']])\n            logger.info(f\"Status: {active_count} jobs ativos, {suspended_count} suspensos, {worker_nodes} nodes\")\n            \n            # Os primeiros 'worker_nodes' jobs devem estar ativos, os demais suspensos\n            for i, job in enumerate(pending_jobs):\n                should_be_suspended = i \u003e= worker_nodes\n                is_suspended = job['suspended']\n                \n                # Se o estado atual n√£o corresponde ao estado desejado, aplica o patch\n                if should_be_suspended != is_suspended:\n                    try:\n                        patch_body = {\"spec\": {\"suspend\": should_be_suspended}}\n                        batch.patch_namespaced_job(job['name'], \"default\", patch_body)\n                        \n                        if should_be_suspended:\n                            logger.info(f\"Job {job['name']} suspenso (posi√ß√£o {i+1} na fila)\")\n                        else:\n                            logger.info(f\"Job {job['name']} liberado para execu√ß√£o (posi√ß√£o {i+1} na fila)\")\n                            \n                        # Breve pausa para permitir que o Kubernetes processe o patch\n                        time.sleep(0.5)\n                    except Exception as e:\n                        logger.error(f\"Falha ao atualizar job {job['name']}: {e}\")\n    except Exception as e:\n        logger.error(f\"Erro em enforce_queue_order: {e}\")\n\ndef monitor_job_distribution():\n    \"\"\"Monitora e loga como os jobs est√£o distribu√≠dos entre os nodes\"\"\"\n    try:\n        pods = core.list_namespaced_pod(\"default\").items\n        jobs_per_node = {}\n        \n        for pod in pods:\n            if pod.metadata.owner_references:\n                for owner in pod.metadata.owner_references:\n                    if owner.kind == 'Job':\n                        job_name = owner.name\n                        node_name = pod.spec.node_name\n                        \n                        if node_name:\n                            if node_name not in jobs_per_node:\n                                jobs_per_node[node_name] = []\n                            jobs_per_node[node_name].append(job_name)\n        \n        # Imprimir distribui√ß√£o atual\n        for node, jobs in jobs_per_node.items():\n            logger.info(f\"Node {node}: {len(jobs)} jobs - {', '.join(jobs)}\")\n        \n        # Verificar se algum node est√° sobrecarregado\n        max_jobs = max([len(jobs) for jobs in jobs_per_node.values()]) if jobs_per_node else 0\n        if max_jobs \u003e 1:\n            logger.warning(f\"Alguns nodes est√£o executando mais de um job (m√°ximo: {max_jobs})\")\n    except Exception as e:\n        logger.error(f\"Erro ao monitorar distribui√ß√£o de jobs: {e}\")\n\ndef queue_monitor():\n    \"\"\"Thread que monitora continuamente a fila de jobs\"\"\"\n    while True:\n        try:\n            enforce_queue_order()\n            monitor_job_distribution()\n        except Exception as e:\n            logger.error(f\"Erro no loop de monitoramento: {e}\")\n        \n        # Verifica a cada 5 segundos\n        time.sleep(5)\n\n# Inicia thread para monitorar a fila\nqueue_thread = threading.Thread(target=queue_monitor, daemon=True)\nqueue_thread.start()\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, name, body, logger, **kwargs):\n    logger.info(f\"Novo job detectado: {name}\")\n    \n    # For√ßar verifica√ß√£o imediata\n    threading.Thread(target=enforce_queue_order, daemon=True).start()","recorded":"2025-04-14 16:00:20.524924717","filePath":"null","pinned":false},{"value":"affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: job-name\n                operator: Exists\n            topologyKey: \"kubernetes.io/hostname\"","recorded":"2025-04-14 15:59:48.461892903","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\nimport logging\n\n# Configurar logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"job-controller\")\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    try:\n        nodes = core.list_node().items\n        worker_nodes = [node for node in nodes if not is_controller_node(node)]\n        logger.info(f\"Nodes de trabalho detectados: {len(worker_nodes)}\")\n        return len(worker_nodes)\n    except Exception as e:\n        logger.error(f\"Erro ao buscar nodes: {e}\")\n        return 0\n\ndef get_node_names():\n    \"\"\"Retorna a lista de nomes de nodes de trabalho\"\"\"\n    try:\n        nodes = core.list_node().items\n        worker_nodes = [node.metadata.name for node in nodes if not is_controller_node(node)]\n        return worker_nodes\n    except Exception as e:\n        logger.error(f\"Erro ao obter nomes dos nodes: {e}\")\n        return []\n\ndef get_pods_per_node():\n    \"\"\"Retorna um dicion√°rio com o n√∫mero de pods por node\"\"\"\n    try:\n        pods = core.list_namespaced_pod(\"default\").items\n        node_pods = {}\n        \n        # Inicializar contagem para todos os nodes\n        for node in get_node_names():\n            node_pods[node] = 0\n        \n        for pod in pods:\n            # Considerar apenas pods ativos\n            if pod.status.phase in ['Running', 'Pending']:\n                node_name = pod.spec.node_name\n                if node_name and node_name in node_pods:\n                    node_pods[node_name] += 1\n        \n        return node_pods\n    except Exception as e:\n        logger.error(f\"Erro ao contar pods por node: {e}\")\n        # Retornar um dicion√°rio vazio se falhar\n        return {node: 0 for node in get_node_names()}\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n    \n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\ndef get_all_jobs():\n    \"\"\"Retorna todos os jobs com status e metadata relevantes\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        job_info = []\n        \n        for job in jobs:\n            # Verificar spec.suspend (pode ser None em jobs antigos)\n            suspended = job.spec.suspend if hasattr(job.spec, 'suspend') and job.spec.suspend is not None else False\n            \n            # Verificar se o job est√° completo ou falhou\n            completed = job.status.succeeded and job.status.succeeded \u003e 0 if hasattr(job.status, 'succeeded') else False\n            failed = job.status.failed and job.status.failed \u003e 0 if hasattr(job.status, 'failed') else False\n            \n            # Verificar se o job est√° ativo\n            active = job.status.active and job.status.active \u003e 0 if hasattr(job.status, 'active') else False\n            \n            # Determinar o estado do job\n            state = \"Completed\" if completed else \"Failed\" if failed else \"Active\" if active else \"Pending\"\n            \n            job_info.append({\n                'name': job.metadata.name,\n                'creation_time': job.metadata.creation_timestamp,\n                'suspended': suspended,\n                'state': state,\n                'active': active,\n                'completed': completed,\n                'failed': failed,\n                'object': job  # Guardar o objeto job completo para uso posterior\n            })\n            \n        return job_info\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs: {e}\")\n        return []\n\ndef enforce_queue_order():\n    \"\"\"\n    Aplica a ordem correta da fila e balanceia a carga nos nodes\n    \"\"\"\n    try:\n        with job_lock:\n            worker_nodes = get_num_worker_nodes()\n            if worker_nodes \u003c= 0:\n                logger.warning(\"Nenhum node de trabalho dispon√≠vel\")\n                return\n                \n            # Obt√©m todos os jobs e filtra apenas os que n√£o est√£o completos ou falhados\n            all_jobs = get_all_jobs()\n            pending_jobs = [j for j in all_jobs if j['state'] not in ['Completed', 'Failed']]\n            \n            # Ordena jobs por tempo de cria√ß√£o (mais antigos primeiro)\n            pending_jobs.sort(key=lambda j: j['creation_time'])\n            \n            logger.info(f\"Total de {len(pending_jobs)} jobs pendentes para {worker_nodes} nodes\")\n            \n            # Verificar a carga atual de cada node\n            node_load = get_pods_per_node()\n            \n            # Os primeiros 'worker_nodes' jobs devem estar ativos, os demais suspensos\n            for i, job in enumerate(pending_jobs):\n                should_be_suspended = i \u003e= worker_nodes\n                is_suspended = job['suspended']\n                \n                # Se o estado atual n√£o corresponde ao estado desejado, aplica o patch\n                if should_be_suspended != is_suspended:\n                    try:\n                        patch_body = {\"spec\": {\"suspend\": should_be_suspended}}\n                        response = batch.patch_namespaced_job(job['name'], \"default\", patch_body)\n                        \n                        if should_be_suspended:\n                            logger.info(f\"Job {job['name']} suspenso (posi√ß√£o {i+1} na fila)\")\n                        else:\n                            logger.info(f\"Job {job['name']} liberado para execu√ß√£o (posi√ß√£o {i+1} na fila)\")\n                            # N√£o podemos adicionar nodeSelector, mas podemos monitorar onde o job est√° rodando\n                    except Exception as e:\n                        logger.error(f\"Falha ao atualizar job {job['name']}: {e}\")\n    except Exception as e:\n        logger.error(f\"Erro em enforce_queue_order: {e}\")\n\ndef monitor_running_jobs():\n    \"\"\"Monitora onde os jobs est√£o rodando e equilibra a carga\"\"\"\n    try:\n        # Listar todos os pods ativos\n        pods = core.list_namespaced_pod(\"default\").items\n        jobs_per_node = {}\n        \n        for pod in pods:\n            if pod.status.phase == 'Running' and pod.metadata.owner_references:\n                for owner in pod.metadata.owner_references:\n                    if owner.kind == 'Job':\n                        job_name = owner.name\n                        node_name = pod.spec.node_name\n                        \n                        if node_name:\n                            if node_name not in jobs_per_node:\n                                jobs_per_node[node_name] = []\n                            jobs_per_node[node_name].append(job_name)\n        \n        # Verificar se algum node tem mais de um job\n        overloaded_nodes = {node: jobs for node, jobs in jobs_per_node.items() if len(jobs) \u003e 1}\n        \n        if overloaded_nodes:\n            for node, jobs in overloaded_nodes.items():\n                logger.warning(f\"Node {node} est√° executando m√∫ltiplos jobs: {', '.join(jobs)}\")\n                logger.warning(\"N√£o √© poss√≠vel redistribuir jobs existentes devido √† imutabilidade do template de pod\")\n    except Exception as e:\n        logger.error(f\"Erro ao monitorar jobs em execu√ß√£o: {e}\")\n\ndef queue_monitor():\n    \"\"\"Thread que monitora continuamente a fila de jobs\"\"\"\n    while True:\n        try:\n            enforce_queue_order()\n            monitor_running_jobs()\n        except Exception as e:\n            logger.error(f\"Erro no loop de monitoramento da fila: {e}\")\n        \n        # Verifica a cada 5 segundos\n        time.sleep(5)\n\n# Inicia thread para monitorar a fila\nqueue_thread = threading.Thread(target=queue_monitor, daemon=True)\nqueue_thread.start()\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, name, body, logger, **kwargs):\n    logger.info(f\"Novo job detectado: {name}\")\n    \n    # A l√≥gica de suspens√£o ser√° gerenciada pela thread de monitoramento\n    # Isso garante consist√™ncia total na ordem da fila\n    \n    # Se o job N√ÉO tiver nodeSelector, adicione uma annotation para marcar como \"ainda n√£o alocado\"\n    # N√£o podemos adicionar nodeSelector ap√≥s o job ser criado, ent√£o precisamos fazer isso durante a cria√ß√£o\n    \n    # Podemos for√ßar uma verifica√ß√£o imediata\n    threading.Thread(target=enforce_queue_order, daemon=True).start()","recorded":"2025-04-14 15:58:42.131249040","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\nimport logging\nfrom datetime import datetime\nimport random\n\n# Configurar logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"job-controller\")\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    try:\n        nodes = core.list_node().items\n        # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n        worker_nodes = [node for node in nodes if not is_controller_node(node)]\n        logger.info(f\"Nodes de trabalho detectados: {len(worker_nodes)}\")\n        return len(worker_nodes)\n    except Exception as e:\n        logger.error(f\"Erro ao buscar nodes: {e}\")\n        return 0\n\n\ndef get_node_names():\n    \"\"\"Retorna a lista de nomes de nodes de trabalho\"\"\"\n    try:\n        nodes = core.list_node().items\n        worker_nodes = [\n            node.metadata.name for node in nodes if not is_controller_node(node)]\n        return worker_nodes\n    except Exception as e:\n        logger.error(f\"Erro ao obter nomes dos nodes: {e}\")\n        return []\n\n\ndef get_nodes_with_running_pods():\n    \"\"\"Retorna um dicion√°rio com nodes e os pods que est√£o executando neles\"\"\"\n    try:\n        pods = core.list_namespaced_pod(\"default\").items\n        node_pods = {}\n\n        for pod in pods:\n            # Considerar apenas pods ativos (n√£o completed/failed)\n            if pod.status.phase in ['Running', 'Pending']:\n                node_name = pod.spec.node_name\n                if node_name:\n                    if node_name not in node_pods:\n                        node_pods[node_name] = []\n                    node_pods[node_name].append(pod.metadata.name)\n\n        return node_pods\n    except Exception as e:\n        logger.error(f\"Erro ao obter pods por node: {e}\")\n        return {}\n\n\ndef get_least_busy_node():\n    \"\"\"Retorna o node com menos pods em execu√ß√£o\"\"\"\n    try:\n        node_pods = get_nodes_with_running_pods()\n        all_nodes = get_node_names()\n\n        # Adicionar nodes que n√£o t√™m pods\n        for node in all_nodes:\n            if node not in node_pods:\n                node_pods[node] = []\n\n        # Ordenar por n√∫mero de pods (do menor para o maior)\n        nodes_by_load = sorted(node_pods.items(), key=lambda x: len(x[1]))\n\n        if nodes_by_load:\n            least_busy_node = nodes_by_load[0][0]\n            logger.info(f\"Node menos ocupado: {least_busy_node} com {\n                        len(nodes_by_load[0][1])} pods\")\n            return least_busy_node\n\n        return None\n    except Exception as e:\n        logger.error(f\"Erro ao encontrar node menos ocupado: {e}\")\n        return None\n\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n\n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\n\ndef get_all_jobs():\n    \"\"\"Retorna todos os jobs com status e metadata relevantes\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        job_info = []\n\n        for job in jobs:\n            # Verificar spec.suspend (pode ser None em jobs antigos)\n            suspended = job.spec.suspend if hasattr(\n                job.spec, 'suspend') and job.spec.suspend is not None else False\n\n            # Verificar se o job est√° completo ou falhou\n            completed = job.status.succeeded and job.status.succeeded \u003e 0 if hasattr(\n                job.status, 'succeeded') else False\n            failed = job.status.failed and job.status.failed \u003e 0 if hasattr(\n                job.status, 'failed') else False\n\n            # Verificar se o job est√° ativo\n            active = job.status.active and job.status.active \u003e 0 if hasattr(\n                job.status, 'active') else False\n\n            # Determinar o estado do job\n            state = \"Completed\" if completed else \"Failed\" if failed else \"Active\" if active else \"Pending\"\n\n            job_info.append({\n                'name': job.metadata.name,\n                'creation_time': job.metadata.creation_timestamp,\n                'suspended': suspended,\n                'state': state,\n                'active': active,\n                'completed': completed,\n                'failed': failed,\n                'object': job  # Guardar o objeto job completo para uso posterior\n            })\n\n        return job_info\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs: {e}\")\n        return []\n\n\ndef enforce_queue_order():\n    \"\"\"\n    Aplica a ordem correta da fila e distribui jobs entre os nodes\n    \"\"\"\n    try:\n        with job_lock:\n            worker_nodes = get_num_worker_nodes()\n            if worker_nodes \u003c= 0:\n                logger.warning(\"Nenhum node de trabalho dispon√≠vel\")\n                return\n\n            # Obt√©m todos os jobs e filtra apenas os que n√£o est√£o completos ou falhados\n            all_jobs = get_all_jobs()\n            pending_jobs = [j for j in all_jobs if j['state']\n                            not in ['Completed', 'Failed']]\n\n            # Ordena jobs por tempo de cria√ß√£o (mais antigos primeiro)\n            pending_jobs.sort(key=lambda j: j['creation_time'])\n\n            logger.info(f\"Total de {len(pending_jobs)} jobs pendentes para {\n                        worker_nodes} nodes\")\n\n            # Os primeiros 'worker_nodes' jobs devem estar ativos, os demais suspensos\n            for i, job in enumerate(pending_jobs):\n                should_be_suspended = i \u003e= worker_nodes\n                is_suspended = job['suspended']\n\n                # Se o estado atual n√£o corresponde ao estado desejado, aplica o patch\n                if should_be_suspended != is_suspended:\n                    try:\n                        if should_be_suspended:\n                            # Suspender o job\n                            patch_body = {\"spec\": {\"suspend\": True}}\n                            response = batch.patch_namespaced_job(\n                                job['name'], \"default\", patch_body)\n                            logger.info(\n                                f\"Job {job['name']} suspenso (posi√ß√£o {i+1} na fila)\")\n                        else:\n                            # Liberar o job e direcionar para um node espec√≠fico\n                            target_node = get_least_busy_node()\n\n                            if target_node:\n                                patch_body = {\n                                    \"spec\": {\n                                        \"suspend\": False,\n                                        \"template\": {\n                                            \"spec\": {\n                                                \"nodeSelector\": {\n                                                    \"kubernetes.io/hostname\": target_node\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                                response = batch.patch_namespaced_job(\n                                    job['name'], \"default\", patch_body)\n                                logger.info(f\"Job {job['name']} liberado para execu√ß√£o no node {\n                                            target_node} (posi√ß√£o {i+1} na fila)\")\n                            else:\n                                # Se n√£o conseguir encontrar um node espec√≠fico, apenas libera o job\n                                patch_body = {\"spec\": {\"suspend\": False}}\n                                response = batch.patch_namespaced_job(\n                                    job['name'], \"default\", patch_body)\n                                logger.info(\n                                    f\"Job {job['name']} liberado sem node espec√≠fico (posi√ß√£o {i+1} na fila)\")\n\n                        # Breve pausa para permitir que o Kubernetes processe o patch\n                        time.sleep(0.5)\n                    except Exception as e:\n                        logger.error(f\"Falha ao atualizar job {\n                                     job['name']}: {e}\")\n    except Exception as e:\n        logger.error(f\"Erro em enforce_queue_order: {e}\")\n\n\ndef queue_monitor():\n    \"\"\"Thread que monitora continuamente a fila de jobs e mant√©m a ordem FIFO\"\"\"\n    while True:\n        try:\n            enforce_queue_order()\n        except Exception as e:\n            logger.error(f\"Erro no loop de monitoramento da fila: {e}\")\n\n        # Verifica a cada 5 segundos\n        time.sleep(5)\n\n\n# Inicia thread para monitorar a fila\nqueue_thread = threading.Thread(target=queue_monitor, daemon=True)\nqueue_thread.start()\n\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, logger, **kwargs):\n    job_name = meta['name']\n    logger.info(f\"Novo job detectado: {job_name}\")\n\n    # A l√≥gica de suspens√£o ser√° gerenciada pela thread de monitoramento\n    # Isso garante consist√™ncia total na ordem da fila\n\n    # Podemos for√ßar uma verifica√ß√£o imediata\n    threading.Thread(target=enforce_queue_order, daemon=True).start()\n","recorded":"2025-04-14 15:58:02.581605931","filePath":"null","pinned":false},{"value":"eason: Unprocessable Entity\nHTTP response headers: HTTPHeaderDict({'Audit-Id': 'ca469f56-f658-4891-9843-4ff6d38b3061', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'X-Kubernetes-Pf-Flowschema-Uid': '214f6390-04f4-4532-bda7-5003a7944953', 'X-Kubernetes-Pf-Prioritylevel-Uid': '671e65c8-dea6-47c2-a1dc-b1e79efa7909', 'Date': 'Mon, 14 Apr 2025 18:56:29 GMT', 'Transfer-Encoding': 'chunked'})\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"Job.batch \\\"job-05720fcc-3114-484a-bbf6-e47812dbb5cb\\\" is invalid: spec.template: Invalid value: core.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:\\\"\\\", GenerateName:\\\"\\\", Namespace:\\\"\\\", SelfLink:\\\"\\\", UID:\\\"\\\", ResourceVersion:\\\"\\\", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:\\u003cnil\\u003e, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{\\\"batch.kubernetes.io/controller-uid\\\":\\\"9ed2e972-139e-426f-bd95-4486c8e2e47e\\\", \\\"batch.kubernetes.io/job-name\\\":\\\"job-05720fcc-3114-484a-bbf6-e47812dbb5cb\\\", \\\"controller-uid\\\":\\\"9ed2e972-139e-426f-bd95-4486c8e2e47e\\\", \\\"job-name\\\":\\\"job-05720fcc-3114-484a-bbf6-e47812dbb5cb\\\"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:core.PodSpec{Volumes:[]core.Volume(nil), InitContainers:[]core.Container(nil), Containers:[]core.Container{core.Container{Name:\\\"job-05720fcc-3114-484a-bbf6-e47812dbb5cb-busybox\\\", Image:\\\"busybox\\\", Command:[]string{\\\"sh\\\", \\\"-c\\\", \\\"sleep 10\\\"}, Args:[]string(nil), WorkingDir:\\\"\\\", Ports:[]core.ContainerPort(nil), EnvFrom:[]core.EnvFromSource(nil), Env:[]core.EnvVar(nil), Resources:core.ResourceRequirements{Limits:core.ResourceList(nil), Requests:core.ResourceList{\\\"cpu\\\":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:\\\"1\\\", Format:\\\"DecimalSI\\\"}}, Claims:[]core.ResourceClaim(nil)}, ResizePolicy:[]core.ContainerResizePolicy(nil), RestartPolicy:(*core.ContainerRestartPolicy)(nil), VolumeMounts:[]core.VolumeMount(nil), VolumeDevices:[]core.VolumeDevice(nil), LivenessProbe:(*core.Probe)(nil), ReadinessProbe:(*core.Probe)(nil), StartupProbe:(*core.Probe)(nil), Lifecycle:(*core.Lifecycle)(nil), TerminationMessagePath:\\\"/dev/termination-log\\\", TerminationMessagePolicy:\\\"File\\\", ImagePullPolicy:\\\"Always\\\", SecurityContext:(*core.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]core.EphemeralContainer(nil), RestartPolicy:\\\"Never\\\", TerminationGracePeriodSeconds:(*int64)(0xc0033a7fc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:\\\"ClusterFirst\\\", NodeSelector:map[string]string{\\\"kubernetes.io/hostname\\\":\\\"kind-worker\\\"}, ServiceAccountName:\\\"\\\", AutomountServiceAccountToken:(*bool)(nil), NodeName:\\\"\\\", SecurityContext:(*core.PodSecurityContext)(0xc0029e5900), ImagePullSecrets:[]core.LocalObjectReference(nil), Hostname:\\\"\\\", Subdomain:\\\"\\\", SetHostnameAsFQDN:(*bool)(nil), Affinity:(*core.Affinity)(nil), SchedulerName:\\\"default-scheduler\\\", Tolerations:[]core.Toleration(nil), HostAliases:[]core.HostAlias(nil), PriorityClassName:\\\"\\\", Priority:(*int32)(nil), PreemptionPolicy:(*core.PreemptionPolicy)(nil), DNSConfig:(*core.PodDNSConfig)(nil), ReadinessGates:[]core.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), Overhead:core.ResourceList(nil), EnableServiceLinks:(*bool)(nil), TopologySpreadConstraints:[]core.TopologySpreadConstraint(nil), OS:(*core.PodOS)(nil), SchedulingGates:[]core.PodSchedulingGate(nil), ResourceClaims:[]core.PodResourceClaim(nil), Resources:(*core.ResourceRequirements)(nil)}}: field is immutable\",\"reason\":\"Invalid\",\"details\":{\"name\":\"job-05720fcc-3114-484a-bbf6-e47812dbb5cb\",\"group\":\"batch\",\"kind\":\"Job\",\"causes\":[{\"reason\":\"FieldValueInvalid\",\"message\":\"Invalid value: core.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:\\\"\\\", GenerateName:\\\"\\\", Namespace:\\\"\\\", SelfLink:\\\"\\\", UID:\\\"\\\", ResourceVersion:\\\"\\\", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:\\u003cnil\\u003e, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{\\\"batch.kubernetes.io/controller-uid\\\":\\\"9ed2e972-139e-426f-bd95-4486c8e2e47e\\\", \\\"batch.kubernetes.io/job-name\\\":\\\"job-05720fcc-3114-484a-bbf6-e47812dbb5cb\\\", \\\"controller-uid\\\":\\\"9ed2e972-139e-426f-bd95-4486c8e2e47e\\\", \\\"job-name\\\":\\\"job-05720fcc-3114-484a-bbf6-e47812dbb5cb\\\"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:core.PodSpec{Volumes:[]core.Volume(nil), InitContainers:[]core.Container(nil), Containers:[]core.Container{core.Container{Name:\\\"job-05720fcc-3114-484a-bbf6-e47812dbb5cb-busybox\\\", Image:\\\"busybox\\\", Command:[]string{\\\"sh\\\", \\\"-c\\\", \\\"sleep 10\\\"}, Args:[]string(nil), WorkingDir:\\\"\\\", Ports:[]core.ContainerPort(nil), EnvFrom:[]core.EnvFromSource(nil), Env:[]core.EnvVar(nil), Resources:core.ResourceRequirements{Limits:core.ResourceList(nil), Requests:core.ResourceList{\\\"cpu\\\":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:\\\"1\\\", Format:\\\"DecimalSI\\\"}}, Claims:[]core.ResourceClaim(nil)}, ResizePolicy:[]core.ContainerResizePolicy(nil), RestartPolicy:(*core.ContainerRestartPolicy)(nil), VolumeMounts:[]core.VolumeMount(nil), VolumeDevices:[]core.VolumeDevice(nil), LivenessProbe:(*core.Probe)(nil), ReadinessProbe:(*core.Probe)(nil), StartupProbe:(*core.Probe)(nil), Lifecycle:(*core.Lifecycle)(nil), TerminationMessagePath:\\\"/dev/termination-log\\\", TerminationMessagePolicy:\\\"File\\\", ImagePullPolicy:\\\"Always\\\", SecurityContext:(*core.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]core.EphemeralContainer(nil), RestartPolicy:\\\"Never\\\", TerminationGracePeriodSeconds:(*int64)(0xc0033a7fc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:\\\"ClusterFirst\\\", NodeSelector:map[string]string{\\\"kubernetes.io/hostname\\\":\\\"kind-worker\\\"}, ServiceAccountName:\\\"\\\", AutomountServiceAccountToken:(*bool)(nil), NodeName:\\\"\\\", SecurityContext:(*core.PodSecurityContext)(0xc0029e5900), ImagePullSecrets:[]core.LocalObjectReference(nil), Hostname:\\\"\\\", Subdomain:\\\"\\\", SetHostnameAsFQDN:(*bool)(nil), Affinity:(*core.Affinity)(nil), SchedulerName:\\\"default-scheduler\\\", Tolerations:[]core.Toleration(nil), HostAliases:[]core.HostAlias(nil), PriorityClassName:\\\"\\\", Priority:(*int32)(nil), PreemptionPolicy:(*core.PreemptionPolicy)(nil), DNSConfig:(*core.PodDNSConfig)(nil), ReadinessGates:[]core.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), Overhead:core.ResourceList(nil), EnableServiceLinks:(*bool)(nil), TopologySpreadConstraints:[]core.TopologySpreadConstraint(nil), OS:(*core.PodOS)(nil), SchedulingGates:[]core.PodSchedulingGate(nil), ResourceClaims:[]core.PodResourceClaim(nil), Resources:(*core.ResourceRequirements)(nil)}}: field is immutable\",\"field\":\"spec.template\"}]},\"code\":422}","recorded":"2025-04-14 15:57:05.463423614","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\nimport logging\nfrom datetime import datetime\nimport random\n\n# Configurar logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"job-controller\")\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    try:\n        nodes = core.list_node().items\n        # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n        worker_nodes = [node for node in nodes if not is_controller_node(node)]\n        logger.info(f\"Nodes de trabalho detectados: {len(worker_nodes)}\")\n        return len(worker_nodes)\n    except Exception as e:\n        logger.error(f\"Erro ao buscar nodes: {e}\")\n        return 0\n\ndef get_node_names():\n    \"\"\"Retorna a lista de nomes de nodes de trabalho\"\"\"\n    try:\n        nodes = core.list_node().items\n        worker_nodes = [node.metadata.name for node in nodes if not is_controller_node(node)]\n        return worker_nodes\n    except Exception as e:\n        logger.error(f\"Erro ao obter nomes dos nodes: {e}\")\n        return []\n\ndef get_nodes_with_running_pods():\n    \"\"\"Retorna um dicion√°rio com nodes e os pods que est√£o executando neles\"\"\"\n    try:\n        pods = core.list_namespaced_pod(\"default\").items\n        node_pods = {}\n        \n        for pod in pods:\n            # Considerar apenas pods ativos (n√£o completed/failed)\n            if pod.status.phase in ['Running', 'Pending']:\n                node_name = pod.spec.node_name\n                if node_name:\n                    if node_name not in node_pods:\n                        node_pods[node_name] = []\n                    node_pods[node_name].append(pod.metadata.name)\n        \n        return node_pods\n    except Exception as e:\n        logger.error(f\"Erro ao obter pods por node: {e}\")\n        return {}\n\ndef get_least_busy_node():\n    \"\"\"Retorna o node com menos pods em execu√ß√£o\"\"\"\n    try:\n        node_pods = get_nodes_with_running_pods()\n        all_nodes = get_node_names()\n        \n        # Adicionar nodes que n√£o t√™m pods\n        for node in all_nodes:\n            if node not in node_pods:\n                node_pods[node] = []\n        \n        # Ordenar por n√∫mero de pods (do menor para o maior)\n        nodes_by_load = sorted(node_pods.items(), key=lambda x: len(x[1]))\n        \n        if nodes_by_load:\n            least_busy_node = nodes_by_load[0][0]\n            logger.info(f\"Node menos ocupado: {least_busy_node} com {len(nodes_by_load[0][1])} pods\")\n            return least_busy_node\n        \n        return None\n    except Exception as e:\n        logger.error(f\"Erro ao encontrar node menos ocupado: {e}\")\n        return None\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n    \n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\ndef get_all_jobs():\n    \"\"\"Retorna todos os jobs com status e metadata relevantes\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        job_info = []\n        \n        for job in jobs:\n            # Verificar spec.suspend (pode ser None em jobs antigos)\n            suspended = job.spec.suspend if hasattr(job.spec, 'suspend') and job.spec.suspend is not None else False\n            \n            # Verificar se o job est√° completo ou falhou\n            completed = job.status.succeeded and job.status.succeeded \u003e 0 if hasattr(job.status, 'succeeded') else False\n            failed = job.status.failed and job.status.failed \u003e 0 if hasattr(job.status, 'failed') else False\n            \n            # Verificar se o job est√° ativo\n            active = job.status.active and job.status.active \u003e 0 if hasattr(job.status, 'active') else False\n            \n            # Determinar o estado do job\n            state = \"Completed\" if completed else \"Failed\" if failed else \"Active\" if active else \"Pending\"\n            \n            job_info.append({\n                'name': job.metadata.name,\n                'creation_time': job.metadata.creation_timestamp,\n                'suspended': suspended,\n                'state': state,\n                'active': active,\n                'completed': completed,\n                'failed': failed,\n                'object': job  # Guardar o objeto job completo para uso posterior\n            })\n            \n        return job_info\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs: {e}\")\n        return []\n\ndef enforce_queue_order():\n    \"\"\"\n    Aplica a ordem correta da fila e distribui jobs entre os nodes\n    \"\"\"\n    try:\n        with job_lock:\n            worker_nodes = get_num_worker_nodes()\n            if worker_nodes \u003c= 0:\n                logger.warning(\"Nenhum node de trabalho dispon√≠vel\")\n                return\n                \n            # Obt√©m todos os jobs e filtra apenas os que n√£o est√£o completos ou falhados\n            all_jobs = get_all_jobs()\n            pending_jobs = [j for j in all_jobs if j['state'] not in ['Completed', 'Failed']]\n            \n            # Ordena jobs por tempo de cria√ß√£o (mais antigos primeiro)\n            pending_jobs.sort(key=lambda j: j['creation_time'])\n            \n            logger.info(f\"Total de {len(pending_jobs)} jobs pendentes para {worker_nodes} nodes\")\n            \n            # Os primeiros 'worker_nodes' jobs devem estar ativos, os demais suspensos\n            for i, job in enumerate(pending_jobs):\n                should_be_suspended = i \u003e= worker_nodes\n                is_suspended = job['suspended']\n                \n                # Se o estado atual n√£o corresponde ao estado desejado, aplica o patch\n                if should_be_suspended != is_suspended:\n                    try:\n                        if should_be_suspended:\n                            # Suspender o job\n                            patch_body = {\"spec\": {\"suspend\": True}}\n                            response = batch.patch_namespaced_job(job['name'], \"default\", patch_body)\n                            logger.info(f\"Job {job['name']} suspenso (posi√ß√£o {i+1} na fila)\")\n                        else:\n                            # Liberar o job e direcionar para um node espec√≠fico\n                            target_node = get_least_busy_node()\n                            \n                            if target_node:\n                                patch_body = {\n                                    \"spec\": {\n                                        \"suspend\": False,\n                                        \"template\": {\n                                            \"spec\": {\n                                                \"nodeSelector\": {\n                                                    \"kubernetes.io/hostname\": target_node\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                                response = batch.patch_namespaced_job(job['name'], \"default\", patch_body)\n                                logger.info(f\"Job {job['name']} liberado para execu√ß√£o no node {target_node} (posi√ß√£o {i+1} na fila)\")\n                            else:\n                                # Se n√£o conseguir encontrar um node espec√≠fico, apenas libera o job\n                                patch_body = {\"spec\": {\"suspend\": False}}\n                                response = batch.patch_namespaced_job(job['name'], \"default\", patch_body)\n                                logger.info(f\"Job {job['name']} liberado sem node espec√≠fico (posi√ß√£o {i+1} na fila)\")\n                            \n                        # Breve pausa para permitir que o Kubernetes processe o patch\n                        time.sleep(0.5)\n                    except Exception as e:\n                        logger.error(f\"Falha ao atualizar job {job['name']}: {e}\")\n    except Exception as e:\n        logger.error(f\"Erro em enforce_queue_order: {e}\")\n\ndef queue_monitor():\n    \"\"\"Thread que monitora continuamente a fila de jobs e mant√©m a ordem FIFO\"\"\"\n    while True:\n        try:\n            enforce_queue_order()\n        except Exception as e:\n            logger.error(f\"Erro no loop de monitoramento da fila: {e}\")\n        \n        # Verifica a cada 5 segundos\n        time.sleep(5)\n\n# Inicia thread para monitorar a fila\nqueue_thread = threading.Thread(target=queue_monitor, daemon=True)\nqueue_thread.start()\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, logger, **kwargs):\n    job_name = meta['name']\n    logger.info(f\"Novo job detectado: {job_name}\")\n    \n    # A l√≥gica de suspens√£o ser√° gerenciada pela thread de monitoramento\n    # Isso garante consist√™ncia total na ordem da fila\n    \n    # Podemos for√ßar uma verifica√ß√£o imediata\n    threading.Thread(target=enforce_queue_order, daemon=True).start()","recorded":"2025-04-14 15:54:53.494175099","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\nimport logging\nfrom datetime import datetime\n\n# Configurar logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"job-controller\")\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    try:\n        nodes = core.list_node().items\n        # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n        worker_nodes = [node for node in nodes if not is_controller_node(node)]\n        logger.info(f\"Nodes de trabalho detectados: {len(worker_nodes)}\")\n        return len(worker_nodes)\n    except Exception as e:\n        logger.error(f\"Erro ao buscar nodes: {e}\")\n        return 0\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n    \n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\ndef get_all_jobs():\n    \"\"\"Retorna todos os jobs com status e metadata relevantes\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        job_info = []\n        \n        for job in jobs:\n            # Verificar spec.suspend (pode ser None em jobs antigos)\n            suspended = job.spec.suspend if hasattr(job.spec, 'suspend') and job.spec.suspend is not None else False\n            \n            # Verificar se o job est√° completo ou falhou\n            completed = job.status.succeeded and job.status.succeeded \u003e 0 if hasattr(job.status, 'succeeded') else False\n            failed = job.status.failed and job.status.failed \u003e 0 if hasattr(job.status, 'failed') else False\n            \n            # Verificar se o job est√° ativo\n            active = job.status.active and job.status.active \u003e 0 if hasattr(job.status, 'active') else False\n            \n            # Determinar o estado do job\n            state = \"Completed\" if completed else \"Failed\" if failed else \"Active\" if active else \"Pending\"\n            \n            job_info.append({\n                'name': job.metadata.name,\n                'creation_time': job.metadata.creation_timestamp,\n                'suspended': suspended,\n                'state': state,\n                'active': active,\n                'completed': completed,\n                'failed': failed\n            })\n            \n        return job_info\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs: {e}\")\n        return []\n\ndef enforce_queue_order():\n    \"\"\"\n    Aplica a ordem correta da fila:\n    1. Suspende todos os jobs exceto os N mais antigos (onde N √© o n√∫mero de nodes)\n    2. Garante que apenas os N jobs mais antigos estejam ativos\n    \"\"\"\n    try:\n        with job_lock:\n            worker_nodes = get_num_worker_nodes()\n            if worker_nodes \u003c= 0:\n                logger.warning(\"Nenhum node de trabalho dispon√≠vel\")\n                return\n                \n            # Obt√©m todos os jobs e filtra apenas os que n√£o est√£o completos ou falhados\n            all_jobs = get_all_jobs()\n            pending_jobs = [j for j in all_jobs if j['state'] not in ['Completed', 'Failed']]\n            \n            # Ordena jobs por tempo de cria√ß√£o (mais antigos primeiro)\n            pending_jobs.sort(key=lambda j: j['creation_time'])\n            \n            logger.info(f\"Total de {len(pending_jobs)} jobs pendentes para {worker_nodes} nodes\")\n            \n            # Os primeiros 'worker_nodes' jobs devem estar ativos, os demais suspensos\n            for i, job in enumerate(pending_jobs):\n                should_be_suspended = i \u003e= worker_nodes\n                is_suspended = job['suspended']\n                \n                # Se o estado atual n√£o corresponde ao estado desejado, aplica o patch\n                if should_be_suspended != is_suspended:\n","recorded":"2025-04-14 15:54:47.627520883","filePath":"null","pinned":false},{"value":"                    try:\n                        patch_body = {\"spec\": {\"suspend\": should_be_suspended}}\n                        response = batch.patch_namespaced_job(job['name'], \"default\", patch_body)\n                        \n                        if should_be_suspended:\n                            logger.info(f\"Job {job['name']} suspenso (posi√ß√£o {i+1} na fila)\")\n                        else:\n                            logger.info(f\"Job {job['name']} liberado para execu√ß√£o (posi√ß√£o {i+1} na fila)\")\n                            \n                        # Breve pausa para permitir que o Kubernetes processe o patch\n                        time.sleep(0.5)\n                    except Exception as e:\n                        logger.error(f\"Falha ao atualizar job {job['name']}: {e}\")\n    except Exception as e:\n        logger.error(f\"Erro em enforce_queue_order: {e}\")\n\ndef queue_monitor():\n    \"\"\"Thread que monitora continuamente a fila de jobs e mant√©m a ordem FIFO\"\"\"\n    while True:\n        try:\n            enforce_queue_order()\n        except Exception as e:\n            logger.error(f\"Erro no loop de monitoramento da fila: {e}\")\n        \n        # Verifica a cada 5 segundos\n        time.sleep(5)\n\n# Inicia thread para monitorar a fila\nqueue_thread = threading.Thread(target=queue_monitor, daemon=True)\nqueue_thread.start()\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, logger, **kwargs):\n    job_name = meta['name']\n    logger.info(f\"Novo job detectado: {job_name}\")\n    \n    # A l√≥gica de suspens√£o ser√° gerenciada pela thread de monitoramento\n    # Isso garante consist√™ncia total na ordem da fila\n    \n    # Podemos for√ßar uma verifica√ß√£o imediata\n    threading.Thread(target=enforce_queue_order, daemon=True).start()\n","recorded":"2025-04-14 15:54:45.727163707","filePath":"null","pinned":false},{"value":"\twg.Add(1)\n\t// go func() {\n","recorded":"2025-04-14 15:43:22.293896162","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\nimport logging\nfrom datetime import datetime\n\n# Configurar logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"job-controller\")\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    try:\n        nodes = core.list_node().items\n        # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n        worker_nodes = [node for node in nodes if not is_controller_node(node)]\n        logger.info(f\"Nodes de trabalho detectados: {len(worker_nodes)}\")\n        return len(worker_nodes)\n    except Exception as e:\n        logger.error(f\"Erro ao buscar nodes: {e}\")\n        return 0\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n    \n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\ndef get_all_jobs():\n    \"\"\"Retorna todos os jobs com status e metadata relevantes\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        job_info = []\n        \n        for job in jobs:\n            # Verificar spec.suspend (pode ser None em jobs antigos)\n            suspended = job.spec.suspend if hasattr(job.spec, 'suspend') and job.spec.suspend is not None else False\n            \n            # Verificar se o job est√° completo ou falhou\n            completed = job.status.succeeded and job.status.succeeded \u003e 0 if hasattr(job.status, 'succeeded') else False\n            failed = job.status.failed and job.status.failed \u003e 0 if hasattr(job.status, 'failed') else False\n            \n            # Verificar se o job est√° ativo\n            active = job.status.active and job.status.active \u003e 0 if hasattr(job.status, 'active') else False\n            \n            # Determinar o estado do job\n            state = \"Completed\" if completed else \"Failed\" if failed else \"Active\" if active else \"Pending\"\n            \n            job_info.append({\n                'name': job.metadata.name,\n                'creation_time': job.metadata.creation_timestamp,\n                'suspended': suspended,\n                'state': state,\n                'active': active,\n                'completed': completed,\n                'failed': failed\n            })\n            \n        return job_info\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs: {e}\")\n        return []\n\ndef enforce_queue_order():\n    \"\"\"\n    Aplica a ordem correta da fila:\n    1. Suspende todos os jobs exceto os N mais antigos (onde N √© o n√∫mero de nodes)\n    2. Garante que apenas os N jobs mais antigos estejam ativos\n    \"\"\"\n    try:\n        with job_lock:\n            worker_nodes = get_num_worker_nodes()\n            if worker_nodes \u003c= 0:\n                logger.warning(\"Nenhum node de trabalho dispon√≠vel\")\n                return\n                \n            # Obt√©m todos os jobs e filtra apenas os que n√£o est√£o completos ou falhados\n            all_jobs = get_all_jobs()\n            pending_jobs = [j for j in all_jobs if j['state'] not in ['Completed', 'Failed']]\n            \n            # Ordena jobs por tempo de cria√ß√£o (mais antigos primeiro)\n            pending_jobs.sort(key=lambda j: j['creation_time'])\n            \n            logger.info(f\"Total de {len(pending_jobs)} jobs pendentes para {worker_nodes} nodes\")\n            \n            # Os primeiros 'worker_nodes' jobs devem estar ativos, os demais suspensos\n            for i, job in enumerate(pending_jobs):\n                should_be_suspended = i \u003e= worker_nodes\n                is_suspended = job['suspended']\n                \n                # Se o estado atual n√£o corresponde ao estado desejado, aplica o patch\n                if should_be_suspended != is_suspended:\n                    try:\n                        patch_body = {\"spec\": {\"suspend\": should_be_suspended}}\n                        response = batch.patch_namespaced_job(job['name'], \"default\", patch_body)\n                        \n                        if should_be_suspended:\n                            logger.info(f\"Job {job['name']} suspenso (posi√ß√£o {i+1} na fila)\")\n                        else:\n                            logger.info(f\"Job {job['name']} liberado para execu√ß√£o (posi√ß√£o {i+1} na fila)\")\n                            \n                        # Breve pausa para permitir que o Kubernetes processe o patch\n                        time.sleep(0.5)\n                    except Exception as e:\n                        logger.error(f\"Falha ao atualizar job {job['name']}: {e}\")\n    except Exception as e:\n        logger.error(f\"Erro em enforce_queue_order: {e}\")\n\ndef queue_monitor():\n    \"\"\"Thread que monitora continuamente a fila de jobs e mant√©m a ordem FIFO\"\"\"\n    while True:\n        try:\n            enforce_queue_order()\n        except Exception as e:\n            logger.error(f\"Erro no loop de monitoramento da fila: {e}\")\n        \n        # Verifica a cada 5 segundos\n        time.sleep(5)\n\n# Inicia thread para monitorar a fila\nqueue_thread = threading.Thread(target=queue_monitor, daemon=True)\nqueue_thread.start()\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, logger, **kwargs):\n    job_name = meta['name']\n    logger.info(f\"Novo job detectado: {job_name}\")\n    \n    # A l√≥gica de suspens√£o ser√° gerenciada pela thread de monitoramento\n    # Isso garante consist√™ncia total na ordem da fila\n    \n    # Podemos for√ßar uma verifica√ß√£o imediata\n    threading.Thread(target=enforce_queue_order, daemon=True).start()","recorded":"2025-04-14 15:36:50.427321598","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\nimport logging\n\n# Configurar logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"job-controller\")\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    try:\n        nodes = core.list_node().items\n        # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n        worker_nodes = [node for node in nodes if not is_controller_node(node)]\n        logger.info(f\"Nodes de trabalho detectados: {len(worker_nodes)}\")\n        return len(worker_nodes)\n    except Exception as e:\n        logger.error(f\"Erro ao buscar nodes: {e}\")\n        return 0\n\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n\n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\n\ndef get_active_jobs():\n    \"\"\"Retorna uma lista de jobs ativos (n√£o suspensos e em execu√ß√£o)\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        active_jobs = []\n\n        for job in jobs:\n            # Verificar spec.suspend (pode ser None em jobs antigos)\n            suspended = job.spec.suspend if hasattr(\n                job.spec, 'suspend') and job.spec.suspend is not None else False\n\n            # Um job est√° ativo se (status.active \u003e 0 ou status.active existe) e n√£o est√° suspenso\n            is_active = job.status.active and job.status.active \u003e 0 and not suspended\n\n            if is_active:\n                active_jobs.append(job)\n                logger.info(f\"Job ativo: {job.metadata.name}\")\n\n        return active_jobs\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs ativos: {e}\")\n        return []\n\n\ndef get_suspended_jobs():\n    \"\"\"Retorna uma lista de jobs suspensos\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        suspended_jobs = []\n\n        for job in jobs:\n            # Verificar se o job est√° suspenso\n            if hasattr(job.spec, 'suspend') and job.spec.suspend:\n                suspended_jobs.append(job)\n                logger.info(f\"Job suspenso: {job.metadata.name}\")\n\n        return suspended_jobs\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs suspensos: {e}\")\n        return []\n\n\ndef check_and_unsuspend_jobs():\n    \"\"\"Verifica periodicamente se jobs suspensos podem ser ativados\"\"\"\n    while True:\n        try:\n            with job_lock:\n                active_jobs = get_active_jobs()\n                worker_nodes = get_num_worker_nodes()\n                free_slots = worker_nodes - len(active_jobs)\n\n                logger.info(f\"Status: {len(active_jobs)} jobs ativos, {\n                            worker_nodes} nodes, {free_slots} slots livres\")\n\n                if free_slots \u003e 0:\n                    # Procura jobs suspensos para ativar\n                    suspended_jobs = get_suspended_jobs()\n\n                    if suspended_jobs:\n                        # Ordena por tempo de cria√ß√£o (mais antigos primeiro)\n                        suspended_jobs.sort(\n                            key=lambda j: j.metadata.creation_timestamp)\n\n                        # Ativa at√© free_slots jobs suspensos\n                        for job in suspended_jobs[:free_slots]:\n                            try:\n                                logger.info(f\"Tentando liberar job suspenso: {\n                                            job.metadata.name}\")\n                                patch_body = {\"spec\": {\"suspend\": False}}\n                                response = batch.patch_namespaced_job(\n                                    job.metadata.name,\n                                    \"default\",\n                                    patch_body\n                                )\n                                logger.info(f\"Job {job.metadata.name} liberado com sucesso. Status do patch: {\n                                            response.status}\")\n\n                                # Pausa para garantir que o Kubernetes processe o patch\n                                time.sleep(1)\n                            except Exception as e:\n                                logger.error(f\"Falha ao liberar job {\n                                             job.metadata.name}: {e}\")\n        except Exception as e:\n            logger.error(\n                f\"Erro no loop principal de check_and_unsuspend_jobs: {e}\")\n\n        # Verifica a cada 10 segundos\n        time.sleep(10)\n\n\n# Inicia thread para checar e liberar jobs periodicamente\nunsuspend_thread = threading.Thread(\n    target=check_and_unsuspend_jobs, daemon=True)\nunsuspend_thread.start()\n\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, logger, **kwargs):\n    job_name = meta['name']\n    logger.info(f\"Processando cria√ß√£o do job: {job_name}\")\n\n    with job_lock:\n        # Verificar se o job j√° tem spec.suspend definido\n        is_already_suspended = spec.get('suspend', False)\n        if is_already_suspended:\n            logger.info(f\"Job {job_name} j√° est√° suspenso. Ignorando.\")\n            return\n\n        # Contar jobs ativos antes de considerar o job atual\n        active_jobs = get_active_jobs()\n        worker_nodes = get_num_worker_nodes()\n\n        logger.info(f\"Status atual: {len(active_jobs)} jobs ativos, {\n                    worker_nodes} nodes\")\n\n        # Se o n√∫mero de jobs ativos atingiu ou excedeu o n√∫mero de nodes\n        if len(active_jobs) \u003e= worker_nodes:\n            try:\n                # Fazer o patch diretamente usando o cliente Kubernetes\n                patch_body = {\"spec\": {\"suspend\": True}}\n                response = batch.patch_namespaced_job(\n                    job_name, \"default\", patch_body)\n                logger.info(f\"Job {job_name} suspenso. Status do patch: {\n                            response.status}\")\n","recorded":"2025-04-14 15:36:46.635924147","filePath":"null","pinned":false},{"value":"            except Exception as e:\n","recorded":"2025-04-14 15:36:44.238061068","filePath":"null","pinned":false},{"value":"                logger.error(f\"Falha ao suspender job {job_name}: {e}\")\n","recorded":"2025-04-14 15:36:42.916579698","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\nimport logging\n\n# Configurar logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"job-controller\")\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    try:\n        nodes = core.list_node().items\n        # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n        worker_nodes = [node for node in nodes if not is_controller_node(node)]\n        logger.info(f\"Nodes de trabalho detectados: {len(worker_nodes)}\")\n        return len(worker_nodes)\n    except Exception as e:\n        logger.error(f\"Erro ao buscar nodes: {e}\")\n        return 0\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n    \n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\ndef get_active_jobs():\n    \"\"\"Retorna uma lista de jobs ativos (n√£o suspensos e em execu√ß√£o)\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        active_jobs = []\n        \n        for job in jobs:\n            # Verificar spec.suspend (pode ser None em jobs antigos)\n            suspended = job.spec.suspend if hasattr(job.spec, 'suspend') and job.spec.suspend is not None else False\n            \n            # Um job est√° ativo se (status.active \u003e 0 ou status.active existe) e n√£o est√° suspenso\n            is_active = job.status.active and job.status.active \u003e 0 and not suspended\n            \n            if is_active:\n                active_jobs.append(job)\n                logger.info(f\"Job ativo: {job.metadata.name}\")\n        \n        return active_jobs\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs ativos: {e}\")\n        return []\n\ndef get_suspended_jobs():\n    \"\"\"Retorna uma lista de jobs suspensos\"\"\"\n    try:\n        jobs = batch.list_namespaced_job(\"default\").items\n        suspended_jobs = []\n        \n        for job in jobs:\n            # Verificar se o job est√° suspenso\n            if hasattr(job.spec, 'suspend') and job.spec.suspend:\n                suspended_jobs.append(job)\n                logger.info(f\"Job suspenso: {job.metadata.name}\")\n        \n        return suspended_jobs\n    except Exception as e:\n        logger.error(f\"Erro ao listar jobs suspensos: {e}\")\n        return []\n\ndef check_and_unsuspend_jobs():\n    \"\"\"Verifica periodicamente se jobs suspensos podem ser ativados\"\"\"\n    while True:\n        try:\n            with job_lock:\n                active_jobs = get_active_jobs()\n                worker_nodes = get_num_worker_nodes()\n                free_slots = worker_nodes - len(active_jobs)\n                \n                logger.info(f\"Status: {len(active_jobs)} jobs ativos, {worker_nodes} nodes, {free_slots} slots livres\")\n                \n                if free_slots \u003e 0:\n                    # Procura jobs suspensos para ativar\n                    suspended_jobs = get_suspended_jobs()\n                    \n                    if suspended_jobs:\n                        # Ordena por tempo de cria√ß√£o (mais antigos primeiro)\n                        suspended_jobs.sort(key=lambda j: j.metadata.creation_timestamp)\n                        \n                        # Ativa at√© free_slots jobs suspensos\n                        for job in suspended_jobs[:free_slots]:\n                            try:\n                                logger.info(f\"Tentando liberar job suspenso: {job.metadata.name}\")\n                                patch_body = {\"spec\": {\"suspend\": False}}\n                                response = batch.patch_namespaced_job(\n                                    job.metadata.name, \n                                    \"default\", \n                                    patch_body\n                                )\n                                logger.info(f\"Job {job.metadata.name} liberado com sucesso. Status do patch: {response.status}\")\n                                \n                                # Pausa para garantir que o Kubernetes processe o patch\n                                time.sleep(1)\n                            except Exception as e:\n                                logger.error(f\"Falha ao liberar job {job.metadata.name}: {e}\")\n        except Exception as e:\n            logger.error(f\"Erro no loop principal de check_and_unsuspend_jobs: {e}\")\n        \n        # Verifica a cada 10 segundos\n        time.sleep(10)\n\n# Inicia thread para checar e liberar jobs periodicamente\nunsuspend_thread = threading.Thread(target=check_and_unsuspend_jobs, daemon=True)\nunsuspend_thread.start()\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, logger, **kwargs):\n    job_name = meta['name']\n    logger.info(f\"Processando cria√ß√£o do job: {job_name}\")\n    \n    with job_lock:\n        # Verificar se o job j√° tem spec.suspend definido\n        is_already_suspended = spec.get('suspend', False)\n        if is_already_suspended:\n            logger.info(f\"Job {job_name} j√° est√° suspenso. Ignorando.\")\n            return\n        \n        # Contar jobs ativos antes de considerar o job atual\n        active_jobs = get_active_jobs()\n        worker_nodes = get_num_worker_nodes()\n        \n        logger.info(f\"Status atual: {len(active_jobs)} jobs ativos, {worker_nodes} nodes\")\n        \n        # Se o n√∫mero de jobs ativos atingiu ou excedeu o n√∫mero de nodes\n        if len(active_jobs) \u003e= worker_nodes:\n            try:\n                # Fazer o patch diretamente usando o cliente Kubernetes\n                patch_body = {\"spec\": {\"suspend\": True}}\n                response = batch.patch_namespaced_job(job_name, \"default\", patch_body)\n                logger.info(f\"Job {job_name} suspenso. Status do patch: {response.status}\")\n            except Exception as e:\n                logger.error(f\"Falha ao suspender job {job_name}: {e}\")","recorded":"2025-04-14 15:32:45.824725520","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    nodes = core.list_node().items\n    # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n    worker_nodes = [node for node in nodes if not is_controller_node(node)]\n    return len(worker_nodes)\n\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n\n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\n\ndef get_active_jobs_num():\n    \"\"\"Retorna o n√∫mero de jobs ativos (n√£o suspensos e em execu√ß√£o)\"\"\"\n    jobs = batch.list_namespaced_job(\"default\").items\n    active_count = 0\n\n    for job in jobs:\n        # Um job est√° ativo se status.active \u003e 0 e spec.suspend != True\n        if job.status.active and job.status.active \u003e 0:\n            if not job.spec.suspend:\n                active_count += 1\n                print(f\"Job ativo: {job.metadata.name}\")\n\n    return active_count\n\n\ndef check_and_unsuspend_jobs():\n    \"\"\"Verifica periodicamente se jobs suspensos podem ser ativados\"\"\"\n    while True:\n        with job_lock:\n            free_slots = get_num_worker_nodes() - get_active_jobs_num()\n\n            if free_slots \u003e 0:\n                # Procura jobs suspensos para ativar\n                jobs = batch.list_namespaced_job(\"default\").items\n                suspended_jobs = [job for job in jobs if job.spec.suspend]\n\n                # Ordena por tempo de cria√ß√£o (mais antigos primeiro)\n                suspended_jobs.sort(\n                    key=lambda j: j.metadata.creation_timestamp)\n\n                # Ativa at√© free_slots jobs suspensos\n                for job in suspended_jobs[:free_slots]:\n                    print(f\"Liberando job suspenso: {job.metadata.name}\")\n                    patch = {\"spec\": {\"suspend\": False}}\n                    batch.patch_namespaced_job(\n                        job.metadata.name, \"default\", patch)\n\n        # Verifica a cada 5 segundos\n        time.sleep(2)\n\n\n# Inicia thread para checar e liberar jobs periodicamente\nunsuspend_thread = threading.Thread(\n    target=check_and_unsuspend_jobs, daemon=True)\nunsuspend_thread.start()\n\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, patch, logger, **kwargs):\n    with job_lock:\n        # Verificar se o job j√° tem spec.suspend definido\n        is_already_suspended = spec.get('suspend', False)\n        if is_already_suspended:\n            # Se j√° est√° suspenso, n√£o fazemos nada\n            return\n\n        # Contar jobs ativos antes de considerar o job atual\n        active_jobs = get_active_jobs_num()\n        worker_nodes = get_num_worker_nodes()\n\n        # Se o n√∫mero de jobs ativos atingiu ou excedeu o n√∫mero de nodes\n        if active_jobs \u003e= worker_nodes:\n            # Usar o objeto patch corretamente\n            patch.update({\"spec\": {\"suspend\": True}})\n            print(f\"Suspendendo job {\n                  meta['name']} - Active jobs: {active_jobs}, Worker nodes: {worker_nodes}\")\n","recorded":"2025-04-14 15:32:41.866756828","filePath":"null","pinned":false},{"value":"            logger.info(\n                f\"Job {meta['name']} suspenso. Ser√° liberado quando um node estiver dispon√≠vel.\")\n","recorded":"2025-04-14 15:32:38.275482748","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    nodes = core.list_node().items\n    # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n    worker_nodes = [node for node in nodes if not is_controller_node(node)]\n    return len(worker_nodes)\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n    \n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\ndef get_active_jobs_num():\n    \"\"\"Retorna o n√∫mero de jobs ativos (n√£o suspensos e em execu√ß√£o)\"\"\"\n    jobs = batch.list_namespaced_job(\"default\").items\n    active_count = 0\n    \n    for job in jobs:\n        # Um job est√° ativo se status.active \u003e 0 e spec.suspend != True\n        if job.status.active and job.status.active \u003e 0:\n            if not job.spec.suspend:\n                active_count += 1\n                print(f\"Job ativo: {job.metadata.name}\")\n    \n    return active_count\n\ndef check_and_unsuspend_jobs():\n    \"\"\"Verifica periodicamente se jobs suspensos podem ser ativados\"\"\"\n    while True:\n        with job_lock:\n            free_slots = get_num_worker_nodes() - get_active_jobs_num()\n            \n            if free_slots \u003e 0:\n                # Procura jobs suspensos para ativar\n                jobs = batch.list_namespaced_job(\"default\").items\n                suspended_jobs = [job for job in jobs if job.spec.suspend]\n                \n                # Ordena por tempo de cria√ß√£o (mais antigos primeiro)\n                suspended_jobs.sort(key=lambda j: j.metadata.creation_timestamp)\n                \n                # Ativa at√© free_slots jobs suspensos\n                for job in suspended_jobs[:free_slots]:\n                    print(f\"Liberando job suspenso: {job.metadata.name}\")\n                    patch = {\"spec\": {\"suspend\": False}}\n                    batch.patch_namespaced_job(job.metadata.name, \"default\", patch)\n        \n        # Verifica a cada 5 segundos\n        time.sleep(5)\n\n# Inicia thread para checar e liberar jobs periodicamente\nunsuspend_thread = threading.Thread(target=check_and_unsuspend_jobs, daemon=True)\nunsuspend_thread.start()\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, patch, logger, **kwargs):\n    with job_lock:\n        # Verificar se o job j√° tem spec.suspend definido\n        is_already_suspended = spec.get('suspend', False)\n        if is_already_suspended:\n            # Se j√° est√° suspenso, n√£o fazemos nada\n            return\n        \n        # Contar jobs ativos antes de considerar o job atual\n        active_jobs = get_active_jobs_num()\n        worker_nodes = get_num_worker_nodes()\n        \n        # Se o n√∫mero de jobs ativos atingiu ou excedeu o n√∫mero de nodes\n        if active_jobs \u003e= worker_nodes:\n            # Usar o objeto patch corretamente\n            patch.update({\"spec\": {\"suspend\": True}})\n            print(f\"Suspendendo job {meta['name']} - Active jobs: {active_jobs}, Worker nodes: {worker_nodes}\")\n            logger.info(f\"Job {meta['name']} suspenso. Ser√° liberado quando um node estiver dispon√≠vel.\")","recorded":"2025-04-14 15:24:25.776167253","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\n# solucao provinda do claude com base no codigo anterior\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    nodes = core.list_node().items\n    # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n    worker_nodes = [node for node in nodes if not is_controller_node(node)]\n    return len(worker_nodes)\n\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n\n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\n\ndef get_active_jobs_num():\n    \"\"\"Retorna o n√∫mero de jobs ativos (n√£o suspensos e em execu√ß√£o)\"\"\"\n    jobs = batch.list_namespaced_job(\"default\").items\n    active_count = 0\n\n    for job in jobs:\n        # Um job est√° ativo se status.active \u003e 0 e spec.suspend != True\n        if job.status.active and job.status.active \u003e 0:\n            if not job.spec.suspend:\n                active_count += 1\n                print(f\"Job ativo: {job.metadata.name}\")\n\n    return active_count\n\n\ndef check_and_unsuspend_jobs():\n    \"\"\"Verifica periodicamente se jobs suspensos podem ser ativados\"\"\"\n    while True:\n        with job_lock:\n            free_slots = get_num_worker_nodes() - get_active_jobs_num()\n\n            if free_slots \u003e 0:\n                # Procura jobs suspensos para ativar\n                jobs = batch.list_namespaced_job(\"default\").items\n                suspended_jobs = [job for job in jobs if job.spec.suspend]\n\n                # Ordena por tempo de cria√ß√£o (mais antigos primeiro)\n                suspended_jobs.sort(\n                    key=lambda j: j.metadata.creation_timestamp)\n\n                # Ativa at√© free_slots jobs suspensos\n                for job in suspended_jobs[:free_slots]:\n                    print(f\"Liberando job suspenso: {job.metadata.name}\")\n                    patch = {\"spec\": {\"suspend\": False}}\n                    batch.patch_namespaced_job(\n                        job.metadata.name, \"default\", patch)\n\n        # Verifica a cada 5 segundos\n        time.sleep(5)\n\n\n# Inicia thread para checar e liberar jobs periodicamente\nunsuspend_thread = threading.Thread(\n    target=check_and_unsuspend_jobs, daemon=True)\nunsuspend_thread.start()\n\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, patch, logger, **kwargs):\n    with job_lock:\n        # Verificar se o job j√° tem spec.suspend definido\n        is_already_suspended = spec.get('suspend', False)\n        if is_already_suspended:\n            # Se j√° est√° suspenso, n√£o fazemos nada\n            return\n\n        # Contar jobs ativos antes de considerar o job atual\n        active_jobs = get_active_jobs_num()\n        worker_nodes = get_num_worker_nodes()\n\n        # Se o n√∫mero de jobs ativos atingiu ou excedeu o n√∫mero de nodes\n        if active_jobs \u003e= worker_nodes:\n            patch.spec = {\"suspend\": True}\n            print(f\"Suspendendo job {\n                  meta['name']} - Active jobs: {active_jobs}, Worker nodes: {worker_nodes}\")\n            logger.info(\n                f\"Job {meta['name']} suspenso. Ser√° liberado quando um node estiver dispon√≠vel.\")\n","recorded":"2025-04-14 15:23:43.689014962","filePath":"null","pinned":false},{"value":"[2025-04-14 15:22:37,637] kopf.activities.auth [INFO    ] Activity 'login_via_client' succeeded.\n[2025-04-14 15:22:37,638] kopf._core.engines.a [INFO    ] Initial authentication has finished.\nJob ativo: 30s-54972\n[2025-04-14 15:22:54,305] kopf.objects         [INFO    ] [default/30s-54972] Handler 'on_job_create' succeeded.\n[2025-04-14 15:22:54,305] kopf.objects         [INFO    ] [default/30s-54972] Creation is processed: 1 succeeded; 0 failed.\nJob ativo: 30s-54972\n[2025-04-14 15:22:55,613] kopf.objects         [INFO    ] [default/10s-54973] Handler 'on_job_create' succeeded.\n[2025-04-14 15:22:55,613] kopf.objects         [INFO    ] [default/10s-54973] Creation is processed: 1 succeeded; 0 failed.\nJob ativo: 10s-54973\nJob ativo: 30s-54972\n[2025-04-14 15:22:57,352] kopf.objects         [ERROR   ] [default/5s-54974] Handler 'on_job_create' failed with an exception. Will retry.\nTraceback (most recent call last):\n  File \"/home/guga/prog/k8s_modcs/queue/tests_py/.venv/lib/python3.13/site-packages/kopf/_core/actions/execution.py\", line 276, in execute_handler_once\n    result = await invoke_handler(\n             ^^^^^^^^^^^^^^^^^^^^^\n    ...\u003c9 lines\u003e...\n    )\n    ^\n  File \"/home/guga/prog/k8s_modcs/queue/tests_py/.venv/lib/python3.13/site-packages/kopf/_core/actions/execution.py\", line 371, in invoke_handler\n    result = await invocation.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n    ...\u003c9 lines\u003e...\n    )\n    ^\n  File \"/home/guga/prog/k8s_modcs/queue/tests_py/.venv/lib/python3.13/site-packages/kopf/_core/actions/invocation.py\", line 139, in invoke\n    await asyncio.shield(future)  # slightly expensive: creates tasks\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/home/guga/prog/k8s_modcs/queue/tests_py/main.py\", line 95, in on_job_create\n    patch.spec = {\"suspend\": True}\n    ^^^^^^^^^^\nAttributeError: property 'spec' of 'Patch' object has no setter\n[2025-04-14 15:22:57,945] kopf.objects         [WARNING ] [default/5s-54974] Patching failed with inconsistencies: (('remove', ('status', 'kopf'), {'progress': {'on_job_create': {'started': '2025-04-14T18:22:56.058486+00:00', 'stopped': None, 'delayed': '2025-04-14T18:23:57.402493+00:00', 'purpose': 'create', 'retries': 1, 'success': False, 'failure': False, 'message': \"property 'spec' of 'Patch' object has no setter\", 'subrefs': None}}}, None),)\nJob ativo: 10s-54973\nJob ativo: 30s-54972\nJob ativo: 5s-54974\nJob ativo: 10s-54973\nJob ativo: 30s-54972\nJob ativo: 5s-54974\n^C[2025-04-14 15:23:06,168] kopf._core.reactor.r [INFO    ] Signal SIGINT is received. Operator is stopping.\n[2025-04-14 15:23:08,175] kopf._core.reactor.q [WARNING ] Unprocessed streams left for [(jobs.v1.batch, '7da22521-0759-4da0-92f7-92d3c93dbb3f')].","recorded":"2025-04-14 15:23:24.408063714","filePath":"null","pinned":false},{"value":"import kopf\nimport kubernetes\nimport threading\nimport time\n\n# Configurar cliente Kubernetes\nkubernetes.config.load_kube_config()\ncore = kubernetes.client.CoreV1Api()\nbatch = kubernetes.client.BatchV1Api()\n\njob_lock = threading.Lock()\n\ndef get_num_worker_nodes():\n    \"\"\"Retorna o n√∫mero de nodes de trabalho (excluindo o controller)\"\"\"\n    nodes = core.list_node().items\n    # Filtrar nodes com taints NoSchedule que geralmente s√£o controllers\n    worker_nodes = [node for node in nodes if not is_controller_node(node)]\n    return len(worker_nodes)\n\ndef is_controller_node(node):\n    \"\"\"Verifica se o node √© um controller baseado em taints\"\"\"\n    if not node.spec.taints:\n        return False\n    \n    for taint in node.spec.taints:\n        if 'NoSchedule' in taint.effect and ('master' in taint.key or 'control-plane' in taint.key):\n            return True\n    return False\n\ndef get_active_jobs_num():\n    \"\"\"Retorna o n√∫mero de jobs ativos (n√£o suspensos e em execu√ß√£o)\"\"\"\n    jobs = batch.list_namespaced_job(\"default\").items\n    active_count = 0\n    \n    for job in jobs:\n        # Um job est√° ativo se status.active \u003e 0 e spec.suspend != True\n        if job.status.active and job.status.active \u003e 0:\n            if not job.spec.suspend:\n                active_count += 1\n                print(f\"Job ativo: {job.metadata.name}\")\n    \n    return active_count\n\ndef check_and_unsuspend_jobs():\n    \"\"\"Verifica periodicamente se jobs suspensos podem ser ativados\"\"\"\n    while True:\n        with job_lock:\n            free_slots = get_num_worker_nodes() - get_active_jobs_num()\n            \n            if free_slots \u003e 0:\n                # Procura jobs suspensos para ativar\n                jobs = batch.list_namespaced_job(\"default\").items\n                suspended_jobs = [job for job in jobs if job.spec.suspend]\n                \n                # Ordena por tempo de cria√ß√£o (mais antigos primeiro)\n                suspended_jobs.sort(key=lambda j: j.metadata.creation_timestamp)\n                \n                # Ativa at√© free_slots jobs suspensos\n                for job in suspended_jobs[:free_slots]:\n                    print(f\"Liberando job suspenso: {job.metadata.name}\")\n                    patch = {\"spec\": {\"suspend\": False}}\n                    batch.patch_namespaced_job(job.metadata.name, \"default\", patch)\n        \n        # Verifica a cada 5 segundos\n        time.sleep(5)\n\n# Inicia thread para checar e liberar jobs periodicamente\nimport threading\nunsuspend_thread = threading.Thread(target=check_and_unsuspend_jobs, daemon=True)\nunsuspend_thread.start()\n\n@kopf.on.create('batch', 'v1', 'jobs')\ndef on_job_create(spec, meta, body, patch, logger, **kwargs):\n    with job_lock:\n        # Verificar se o job j√° tem spec.suspend definido\n        is_already_suspended = spec.get('suspend', False)\n        if is_already_suspended:\n            # Se j√° est√° suspenso, n√£o fazemos nada\n            return\n        \n        # Contar jobs ativos antes de considerar o job atual\n        active_jobs = get_active_jobs_num()\n        worker_nodes = get_num_worker_nodes()\n        \n        # Se o n√∫mero de jobs ativos atingiu ou excedeu o n√∫mero de nodes\n        if active_jobs \u003e= worker_nodes:\n            patch.spec = {\"suspend\": True}\n            print(f\"Suspendendo job {meta['name']} - Active jobs: {active_jobs}, Worker nodes: {worker_nodes}\")\n            logger.info(f\"Job {meta['name']} suspenso. Ser√° liberado quando um node estiver dispon√≠vel.\")","recorded":"2025-04-14 15:14:15.441448592","filePath":"null","pinned":false},{"value":"# Aumentar zoom do cursor com SUPER + =\nbind = SUPER, equal, exec, ~/.local/bin/cursor-zoom.sh\n\n# Resetar zoom com SUPER + 0\nbind = SUPER, 0, exec, ~/.local/bin/cursor-zoom-reset.sh\n","recorded":"2025-04-14 14:55:41.547781297","filePath":"null","pinned":false},{"value":"bind = $mainMod, C, exec, hyprctl keyword cursor:zoom_factor $(awk \"BEGIN {print $(hyprctl getoption cursor:zoom_factor | grep 'float:' | awk '{print $2}') - 0.5}\")\n","recorded":"2025-04-14 14:55:35.704354355","filePath":"null","pinned":false},{"value":"#!/bin/bash\nhyprctl keyword cursor_zoom_factor 1.0\necho 1.0 \u003e /tmp/hypr-cursor-zoom\n","recorded":"2025-04-14 14:55:12.788011564","filePath":"null","pinned":false},{"value":"cursor_zoom_factor","recorded":"2025-04-14 14:52:35.152368214","filePath":"null","pinned":false},{"value":"hyprctl keyword cursor_zoom_factor","recorded":"2025-04-14 14:47:52.570529092","filePath":"null","pinned":false},{"value":"#!/bin/bash\n\n# Arquivo tempor√°rio para armazenar o valor atual do zoom\nZOOM_FILE=\"/tmp/hypr-cursor-zoom\"\nINCREMENT=0.2\nMAX_ZOOM=5.0\n\n# L√™ o valor atual (ou usa 1.0 como padr√£o)\nzoom=$(cat \"$ZOOM_FILE\" 2\u003e/dev/null || echo 1.0)\n\n# Aumenta o zoom\nzoom=$(echo \"$zoom + $INCREMENT\" | bc)\n\n# Limita o valor m√°ximo\nzoom=$(echo \"$zoom $MAX_ZOOM\" | awk '{if ($1 \u003e $2) print $2; else print $1}')\n\n# Aplica e salva\nhyprctl keyword cursor_zoom_factor \"$zoom\"\necho \"$zoom\" \u003e \"$ZOOM_FILE\"\n","recorded":"2025-04-14 14:46:56.166234135","filePath":"null","pinned":false},{"value":"ind = $mainMod SHIFT, mouse_up, exec, hyprctl keyword cursor:zoom_factor $(awk \"BEGIN {print $(hyprctl getoption cursor:zoom_factor | grep 'float:' | awk '{print $2}') - 0.5}\")","recorded":"2025-04-14 14:45:27.419627842","filePath":"null","pinned":false},{"value":"echo $(($(hyprctl getoption misc:cursor_zoom_factor | grep float | awk '{print $2}') + 0.5))\n","recorded":"2025-04-14 14:42:29.095993371","filePath":"null","pinned":false},{"value":"brave --enable-features=UseOzonePlatform --ozone-platform=wayland\n","recorded":"2025-04-14 14:37:50.694190763","filePath":"null","pinned":false},{"value":"cp /usr/share/applications/brave-browser.desktop ~/.local/share/applications/\nnano ~/.local/share/applications/brave-browser.desktop\n","recorded":"2025-04-14 14:37:21.214165019","filePath":"null","pinned":false},{"value":"systemctl --user edit brave-browser\n\nNo files found for brave-browser.service.\nRun 'systemctl edit --user --force --full brave-browser.service' to create a new unit.","recorded":"2025-04-14 14:36:05.484453495","filePath":"null","pinned":false},{"value":"systemctl --user edit brave-browser\n","recorded":"2025-04-14 14:35:59.737979585","filePath":"null","pinned":false},{"value":"env = OZONE_PLATFORM,wayland\n","recorded":"2025-04-14 14:34:26.640524474","filePath":"null","pinned":false},{"value":"env = OZONE_PLATAFORM,wayland\n","recorded":"2025-04-14 14:34:23.282689223","filePath":"null","pinned":false},{"value":"env = XCURSOR_SIZE,7\nenv = HYPRCURSOR_SIZE,24\nenv = XDG_CURRENT_DESKTOP,Hyprland\nenv = XDG_SESSION_TYPE,wayland\nenv = XDG_SESSION_DESKTOP,Hyprland\nenv = GDK_BACKEND,wayland,x11\nenv = SDL_VIDEODRIVER,wayland\nenv = MOZ_ENABLE_WAYLAND,1\nenv = CLUTTER_BACKEND,wayland\n\nenv = QT_QPA_PLATFORM,wayland\nenv = MOZ_ENABLE_WAYLAND,1\nenv = ELECTRON_OZONE_PLATFORM_HINT,auto\n\nenv = OZONE_PLATAFORM,wayland","recorded":"2025-04-14 14:33:28.642416575","filePath":"null","pinned":false},{"value":"--ozone-platform=wayland","recorded":"2025-04-14 14:30:56.515826548","filePath":"null","pinned":false},{"value":"Exec=brave --enable-features=UseOzonePlatform --ozone-platform=wayland %U\n","recorded":"2025-04-14 14:28:00.851413883","filePath":"null","pinned":false},{"value":"nano ~/.local/share/applications/brave-browser.desktop\n","recorded":"2025-04-14 14:27:56.059890835","filePath":"null","pinned":false},{"value":"https://aur.archlinux.org/xzoom.git","recorded":"2025-04-12 23:05:58.400787207","filePath":"null","pinned":false},{"value":"import kopf\nimport threading\nfrom kubernetes import client\n\ncore = client.CoreV1Api()\nbatch = client.BatchV1Api()\njob_lock = threading.Lock()\n\n\ndef getNumNodes():\n    return len(core.list_node().items) - 1  # -1 porque tem o n√≥ de controle\n\n\ndef getActiveJobs():\n    li = batch.list_namespaced_job(\"default\")\n    return [j for j in li.items if j.status.active == 1 and not j.metadata.deletion_timestamp]\n\n\ndef getPendingJobs():\n    li = batch.list_namespaced_job(\"default\")\n    jobs = sorted(li.items, key=lambda j: j.metadata.creation_timestamp)\n    return [j for j in jobs if j.spec.suspend]\n\n\ndef check_and_release_next(logger):\n    with job_lock:\n        active = getActiveJobs()\n        nodes = getNumNodes()\n        logger.info(f\"{len(active)} jobs ativos / {nodes} n√≥s\")\n\n        if len(active) \u003e= nodes:\n            return\n\n        pendentes = getPendingJobs()\n        if pendentes:\n            proximo = pendentes[0]\n            batch.patch_namespaced_job(proximo.metadata.name, \"default\", {\"spec\": {\"suspend\": False}})\n            logger.info(f\"Job liberado: {proximo.metadata.name}\")\n\n\n@kopf.on.create(\"batch\", \"v1\", \"jobs\")\ndef on_job_create(spec, meta, body, patch, logger, **kwargs):\n    with job_lock:\n        # Sempre come√ßa suspenso\n        patch[\"spec\"] = {\"suspend\": True}\n        logger.info(f\"Job {meta['name']} suspenso na cria√ß√£o\")\n    \n    # Checar se pode liberar\n    check_and_release_next(logger)\n\n\n@kopf.timer(\"batch\", \"v1\", \"jobs\", interval=10.0, sharp=True)\ndef on_job_timer(spec, meta, status, logger, **kwargs):\n    # Detecta conclus√£o do job\n    conds = status.get(\"conditions\", [])\n    for cond in conds:\n        if cond.get(\"type\") == \"Complete\" and cond.get(\"status\") == \"True\":\n            logger.info(f\"Job {meta['name']} completo\")\n            check_and_release_next(logger)\n            break\n        elif cond.get(\"type\") == \"Failed\" and cond.get(\"status\") == \"True\":\n            logger.info(f\"Job {meta['name']} falhou\")\n            check_and_release_next(logger)\n            break\n","recorded":"2025-04-12 22:53:27.596169456","filePath":"null","pinned":false},{"value":"def getPendingJobs():\n    li = batch.list_namespaced_job(\"default\")\n    jobs = sorted(li.items, key=lambda j: j.metadata.creation_timestamp)\n    return [j for j in jobs if j.spec.suspend]\n\ndef getActiveJobs():\n    li = batch.list_namespaced_job(\"default\")\n    return [j for j in li.items if j.status.active == 1 and j.status.terminating == 0]\n\n@kopf.on.create(\"batch\", \"v1\", \"jobs\")\ndef on_job_create(spec, meta, body, patch, logger, **kwargs):\n    with job_lock:\n        # Job sempre come√ßa suspenso\n        batch.patch_namespaced_job(meta[\"name\"], \"default\", {\"spec\": {\"suspend\": True}})\n        logger.info(f\"{meta['name']} suspenso inicialmente.\")\n\n        check_and_release_next(logger)\n\ndef check_and_release_next(logger):\n    with job_lock:\n        active_jobs = getActiveJobs()\n        nodes = getNumNodes()\n        logger.info(f\"Temos {len(active_jobs)} ativos e {nodes} nodes dispon√≠veis.\")\n\n        if len(active_jobs) \u003e= nodes:\n            return  # Nenhuma vaga dispon√≠vel\n\n        pending_jobs = getPendingJobs()\n        if pending_jobs:\n            # Liberar o mais antigo\n            job = pending_jobs[0]\n            logger.info(f\"Liberando job {job.metadata.name}\")\n            batch.patch_namespaced_job(job.metadata.name, \"default\", {\"spec\": {\"suspend\": False}})\n","recorded":"2025-04-12 22:50:34.428953445","filePath":"null","pinned":false},{"value":"def getNumNodes():\n    return len(core.list_node().items) - 1  # -1 pois conta o controller\n\n\njob_lock = threading.Lock()\n\n\ndef getActiveJobsNum():\n    print(\"listando jobs\")\n    li = batch.list_namespaced_job(\"default\")\n    i = 0\n    for j in li.items:\n        s = j.status\n        if s.active == 1 and s.terminating == 0:\n            i = i + 1\n            print(f\"ativo {j.metadata.name}\")\n    return i\n\n\n# while 1:\n#     print(f\"Numero de jobs {getActiveJobsNum()} em nodes {getNumNodes()}\")\n#     time.sleep(1)\n\n\n@kopf.on.create(\"batch\", \"v1\", \"jobs\")\ndef on_job_create(spec, meta, body, patch, logger, **kwargs):\n    with job_lock:\n        # o job entra em suspend e depois ele vai ser liberado se\n        # num_active_jobs \u003c num_nodes\n\n        j = getActiveJobsNum()\n        n = getNumNodes()\n        if j \u003e= n:\n            p = {\"spec\": {\"suspend\": True}}\n            batch.patch_namespaced_job(meta[\"name\"], \"default\", p)\n            print(f\"sss {meta[\"name\"]} active jobs = {j}, nodes = {n}\")\n        return\n\n","recorded":"2025-04-12 22:49:02.779575164","filePath":"null","pinned":false},{"value":"        p = {\"spec\": {\"suspend\": True}}\n        batch.patch_namespaced_job(meta[\"name\"], \"default\", p)","recorded":"2025-04-12 22:45:59.962554257","filePath":"null","pinned":false},{"value":" p = {\"spec\": {\"suspend\": True}}\n    batch.patch_namespaced_job(meta[\"name\"], \"default\", p)","recorded":"2025-04-12 22:26:33.058896591","filePath":"null","pinned":false},{"value":" p = {\"spec\": {\"suspend\": True}}\n        batch.patch_namespaced_job(meta[\"name\"], \"default\", p)\n","recorded":"2025-04-12 22:22:39.539647389","filePath":"null","pinned":false},{"value":" p = {\"spec\": {\"suspend\": True}}\n            batch.patch_namespaced_job(meta[\"name\"], \"default\", p)\n","recorded":"2025-04-12 22:22:19.937035181","filePath":"null","pinned":false}]}